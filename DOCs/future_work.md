  ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Š

  ğŸ¯ å½“å‰ JaT-AudioSR æ¶æ„æ¦‚å†µ

  ä»ä»£ç åˆ†æï¼Œå½“å‰é¡¹ç›®æ¶æ„ï¼š
  - æ¨¡å‹: DiT (Diffusion Transformer) with Flow Matching
  - è¾“å…¥: DAC Latent Space (1024 channels, T/512 compression)
  - æ¡ä»¶: Low-resolution latent (lr_norm)
  - æŸå¤±: Charbonnier Loss + Latent Perceptual Loss (Frequency + Multi-Scale + Consistency)
  - è®­ç»ƒ: CFG (Classifier-Free Guidance) + Conditional Noise

  å…³é”®è§‚å¯Ÿ: ç›®å‰ç³»ç»Ÿæ˜¯çº¯ latent-to-latent æ˜ å°„ï¼Œæ²¡æœ‰æ˜¾å¼çš„éŸ³é«˜(F0)æˆ–é¢‘è°±ç‰¹å¾æ£€ç´¢æœºåˆ¶ã€‚

  ---
  1ï¸âƒ£ F0 Methodï¼ˆåŸºé¢‘æå–æ–¹æ³•ï¼‰åˆ†æ

  ğŸ“š ä»€ä¹ˆæ˜¯ F0ï¼Ÿ

  F0 (Fundamental Frequency) = åŸºé¢‘ï¼Œä»£è¡¨å£°éŸ³çš„éŸ³é«˜ç‰¹æ€§

  ğŸ”¬ ä¸»æµ F0 æå–æ–¹æ³•å¯¹æ¯”

  | æ–¹æ³•                 | ç±»å‹          | é€Ÿåº¦                 | å‡†ç¡®åº¦       | é€‚ç”¨åœºæ™¯    |
  |--------------------|-------------|--------------------|-----------|---------|
  | CREPE              | CNN-based   | æ…¢ (æ·±åº¦å­¦ä¹ )           | â­â­â­â­â­ æœ€é«˜  | éŸ³ä¹ã€å¤æ‚éŸ³é¢‘ |
  | Harvest            | DSP-based   | ä¸­ç­‰                 | â­â­â­â­ é«˜    | è¯­éŸ³ã€ç¨³å®šåœºæ™¯ |
  | DIO                | DSP-based   | å¿«                  | â­â­â­ ä¸­ç­‰    | å®æ—¶åº”ç”¨    |
  | ParselMouth        | Praat-based | æå¿« (100x vs CREPE) | â­â­â­ ä¸­ç­‰    | è¯­éŸ³åˆ†æ    |
  | Hybrid (Nanmedian) | å¤šæ–¹æ³•èåˆ       | æ…¢                  | â­â­â­â­â­ æœ€ç¨³å®š | é«˜è´¨é‡åˆæˆ   |

  æ¥æº:
  - https://www.researchgate.net/publication/323276357_CREPE_A_Convolutional_Representation_for_Pitch_Estimation
  - https://www.semanticscholar.org/paper/Harvest:-A-High-Performance-Fundamental-Frequency-Morise/7143d07db6e2a12d0119bcd7dd21ed9
  81072e728
  - https://github.com/voicepaw/so-vits-svc-fork/discussions/318

  âœ… F0 åœ¨éŸ³é¢‘è¶…åˆ†è¾¨ç‡ä¸­çš„æ½œåœ¨å¥½å¤„

  1. éŸ³é«˜ä¿æŒ (Pitch Preservation)

  é—®é¢˜: å½“å‰ç³»ç»Ÿå¯èƒ½æ”¹å˜åŸå§‹éŸ³é¢‘çš„éŸ³é«˜ç‰¹æ€§
  # æ½œåœ¨æ”¹è¿›ï¼šF0 ä½œä¸ºé¢å¤–æ¡ä»¶
  # å½“å‰: model(z_t, t, lr_norm)
  # æ”¹è¿›: model(z_t, t, lr_norm, f0_condition)

  å¥½å¤„:
  - âœ… ä¿æŒæ­Œå”±/ä¹å™¨çš„éŸ³é«˜å‡†ç¡®æ€§
  - âœ… é˜²æ­¢ DiT åœ¨è¶…åˆ†æ—¶å¼•å…¥éŸ³é«˜æ¼‚ç§»
  - âœ… å¯¹éŸ³ä¹è¶…åˆ†è¾¨ç‡ç‰¹åˆ«é‡è¦

  2. é¢‘è°±ç»“æ„å¼•å¯¼ (Spectral Structure Guidance)

  åŸç†: F0 æ›²çº¿å¯ä»¥å¼•å¯¼é«˜é¢‘æ³›éŸ³é‡å»º

  å®ç°æ–¹å¼:
  # ä¼ªä»£ç ç¤ºä¾‹
  f0_curve = extract_f0(lr_audio, method='crepe')  # [B, T]
  harmonic_template = generate_harmonics(f0_curve, num_harmonics=5)
  # å°† harmonic_template ä½œä¸ºé¢å¤– conditioning è¾“å…¥ DiT

  å¥½å¤„:
  - âœ… ç‰©ç†çº¦æŸï¼šé«˜é¢‘åº”è¯¥æ˜¯ F0 çš„å€é¢‘ï¼ˆæ³›éŸ³ç»“æ„ï¼‰
  - âœ… å‡å°‘ "å¹»æƒ³" é«˜é¢‘å†…å®¹çš„é£é™©
  - âœ… æå‡éŸ³ä¹ä¿¡å·çš„è‡ªç„¶åº¦

  3. è¯­éŸ³/éŸ³ä¹åˆ†ç¦»å¤„ç† (Voice/Music Adaptive Processing)

  ç­–ç•¥: æ ¹æ® F0 ç¨³å®šæ€§åˆ¤æ–­å†…å®¹ç±»å‹

  if f0_stability > threshold:
      # è¯­éŸ³ï¼šF0 ç›¸å¯¹ç¨³å®š
      apply_strong_pitch_constraint()
  else:
      # éŸ³ä¹/å¤æ‚éŸ³é¢‘ï¼šF0 å˜åŒ–å¿«
      apply_flexible_spectral_constraint()

  å¥½å¤„:
  - âœ… è‡ªé€‚åº”å¤„ç†ç­–ç•¥
  - âœ… æå‡æ³›åŒ–èƒ½åŠ›

  ---
  2ï¸âƒ£ Index Rateï¼ˆæ£€ç´¢ç‡ï¼‰åˆ†æ

  ğŸ“š ä»€ä¹ˆæ˜¯ Index Rateï¼Ÿ

  Index Rate æ˜¯ RVC (Retrieval-based Voice Conversion) ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼š

  å®šä¹‰: æ§åˆ¶ä»è®­ç»ƒé›†ç‰¹å¾åº“ä¸­æ£€ç´¢çš„ç‰¹å¾å¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ç¨‹åº¦

  å·¥ä½œåŸç†:
  1. è®­ç»ƒæ—¶ä¿å­˜æ‰€æœ‰ HuBERT/å…¶ä»–ç‰¹å¾è¡¨ç¤º
  2. æ¨ç†æ—¶ä½¿ç”¨ FAISS å¿«é€Ÿæ£€ç´¢æœ€ç›¸ä¼¼çš„è®­ç»ƒç‰¹å¾
  3. Index Rate æ§åˆ¶æ£€ç´¢ç‰¹å¾ä¸ç”Ÿæˆç‰¹å¾çš„æ··åˆæ¯”ä¾‹

  æ¥æº:
  - https://en.wikipedia.org/wiki/Retrieval-based_Voice_Conversion
  - https://github.com/RVC-Project/Retrieval-based-Voice-Conversion
  - https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/wiki/FAQ-(Frequently-Asked-Questions)

  âœ… Index Rate åœ¨ JaT-AudioSR ä¸­çš„æ½œåœ¨å¥½å¤„

  1. Latent Feature Retrievalï¼ˆæ½œç©ºé—´ç‰¹å¾æ£€ç´¢ï¼‰

  æ ¸å¿ƒæ€è·¯: å»ºç«‹è®­ç»ƒé›† HR latent ç‰¹å¾åº“

  # è®­ç»ƒé˜¶æ®µ
  class LatentFeatureBank:
      def __init__(self):
          self.hr_features = []  # å­˜å‚¨æ‰€æœ‰ HR latent patches
          self.index = None      # FAISS index

      def add_features(self, hr_latent):
          # å­˜å‚¨ HR latent çš„ patch embeddings
          self.hr_features.append(hr_latent.detach())

      def build_index(self):
          # ä½¿ç”¨ FAISS æ„å»ºå¿«é€Ÿæ£€ç´¢ç´¢å¼•
          import faiss
          features = torch.cat(self.hr_features, dim=0)
          self.index = faiss.IndexFlatL2(features.shape[-1])
          self.index.add(features.cpu().numpy())

  # æ¨ç†é˜¶æ®µ
  def retrieve_and_enhance(pred_hr, feature_bank, index_rate=0.6):
      """
      index_rate: 0.0 = å®Œå…¨ä¾èµ–æ¨¡å‹ç”Ÿæˆ
                  1.0 = å®Œå…¨ä¾èµ–æ£€ç´¢ç‰¹å¾
      """
      # 1. æ£€ç´¢æœ€ç›¸ä¼¼çš„è®­ç»ƒ HR features
      retrieved_features = feature_bank.search(pred_hr, k=1)

      # 2. æ··åˆç”Ÿæˆç‰¹å¾å’Œæ£€ç´¢ç‰¹å¾
      enhanced_hr = (1 - index_rate) * pred_hr + index_rate * retrieved_features
      return enhanced_hr

  å¥½å¤„:
  - âœ… å‡å°‘è‰²è°ƒæ³„æ¼: ç±»ä¼¼ RVCï¼Œé€šè¿‡æ£€ç´¢è®­ç»ƒé›†ç‰¹å¾æ›¿æ¢å¯èƒ½æœ‰é—®é¢˜çš„ç”Ÿæˆç‰¹å¾
  - âœ… æå‡ç»†èŠ‚è¿˜åŸ: è®­ç»ƒé›†ä¸­çš„çœŸå® HR ç‰¹å¾å¯ä»¥æä¾›æ›´çœŸå®çš„é«˜é¢‘ç»†èŠ‚
  - âœ… å¢å¼ºç¨³å®šæ€§: é¿å…æ¨¡å‹ç”Ÿæˆç¦»è°±çš„é«˜é¢‘å†…å®¹

  æ½œåœ¨é—®é¢˜:
  - âš ï¸ è®¡ç®—å¼€é”€: FAISS æ£€ç´¢å¢åŠ æ¨ç†æ—¶é—´
  - âš ï¸ å­˜å‚¨éœ€æ±‚: éœ€è¦å­˜å‚¨æ•´ä¸ªè®­ç»ƒé›†çš„ latent features
  - âš ï¸ è¿‡æ‹Ÿåˆé£é™©: è¿‡é«˜çš„ Index Rate å¯èƒ½å¯¼è‡´è¾“å‡ºè¿‡åº¦ä¾èµ–è®­ç»ƒé›†

  2. Consistency Loss å¢å¼ºï¼ˆä¸€è‡´æ€§æŸå¤±å¢å¼ºï¼‰

  å½“å‰ç³»ç»Ÿ (MOD2) å·²æœ‰ Consistency Lossï¼š
  class HybridConsistencyLoss:
      # ç¡®ä¿ Downsample(HR) â‰ˆ LR

  Index Rate æ”¹è¿›æ–¹å‘:
  def consistency_loss_with_retrieval(pred_hr, lr, feature_bank, index_rate=0.3):
      # 1. æ£€ç´¢è®­ç»ƒé›†ä¸­ä¸ LR æœ€åŒ¹é…çš„ HR
      retrieved_hr = feature_bank.search_by_lr(lr, k=1)

      # 2. æ£€ç´¢ç‰¹å¾ä½œä¸º"å‚è€ƒHR"
      reference_hr = (1 - index_rate) * pred_hr + index_rate * retrieved_hr

      # 3. è®¡ç®—ä¸€è‡´æ€§æŸå¤±
      downsampled_ref = downsample(reference_hr)
      consistency_loss = F.l1_loss(downsampled_ref, lr)

      return consistency_loss

  å¥½å¤„:
  - âœ… ç‰©ç†çº¦æŸæ›´å¼ºï¼šæ£€ç´¢çš„ HR æ˜¯çœŸå®è®­ç»ƒæ ·æœ¬ï¼Œä¿è¯ç‰©ç†å¯è¡Œ
  - âœ… å‡å°‘ "å¹»æƒ³" å†…å®¹ï¼šé¿å…ç”Ÿæˆä¸ LR ä¸ä¸€è‡´çš„é«˜é¢‘

  3. Multi-Scale Retrievalï¼ˆå¤šå°ºåº¦æ£€ç´¢ï¼‰

  ç»“åˆå½“å‰ Multi-Scale Loss:
  # å½“å‰ MOD2 æœ‰ MultiScaleLatentLoss
  # å¯ä»¥ä¸ºæ¯ä¸ª scale å»ºç«‹ç‹¬ç«‹çš„ç‰¹å¾åº“

  class MultiScaleFeatureBank:
      def __init__(self, scales=[1, 2, 4]):
          self.banks = {s: LatentFeatureBank() for s in scales}

      def retrieve_multi_scale(self, pred_hr, index_rate=0.5):
          enhanced = pred_hr.clone()
          for scale, bank in self.banks.items():
              # å¯¹æ¯ä¸ªå°ºåº¦ç‹¬ç«‹æ£€ç´¢å¢å¼º
              downsampled = downsample(pred_hr, scale)
              retrieved = bank.search(downsampled, k=1)
              enhanced += index_rate * upsample(retrieved, scale)
          return enhanced / (1 + len(self.banks) * index_rate)

  å¥½å¤„:
  - âœ… å¤šå°ºåº¦ç‰¹å¾ä¿çœŸ
  - âœ… ç»“æ„æ›´ç¨³å®š

  ---
  ğŸ¯ åœ¨ JaT-AudioSR ä¸­åº”ç”¨çš„å»ºè®®ç­–ç•¥

  ğŸ”¥ æ¨èå®ç°ä¼˜å…ˆçº§

  | ä¼˜å…ˆçº§   | ç‰¹æ€§                           | å®ç°éš¾åº¦ | é¢„æœŸæ”¶ç›Š | æ¨è Index Rate |
  |-------|------------------------------|------|------|---------------|
  | â­â­â­â­â­ | Latent Feature Retrieval     | ä¸­    | é«˜    | 0.3 - 0.6     |
  | â­â­â­â­  | F0-Guided Harmonic Structure | é«˜    | ä¸­-é«˜  | N/A           |
  | â­â­â­   | Multi-Scale Retrieval        | é«˜    | ä¸­    | 0.2 - 0.4     |
  | â­â­    | F0 as Conditioning           | ä¸­    | ä¸­    | N/A           |

  ğŸ“ å®ç°è·¯çº¿å›¾

  Phase 1: F0 Extraction Integration (2-3 å¤©)

  # åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µæå– F0
  import librosa  # æˆ–ä½¿ç”¨ CREPE

  def extract_f0_curve(audio, sr=44100, method='harvest'):
      if method == 'harvest':
          f0 = librosa.pyin(audio, fmin=80, fmax=800)
      elif method == 'crepe':
          # ä½¿ç”¨ torchcrepe
          import torchcrepe
          f0 = torchcrepe.predict(audio, sr, ...)
      return f0

  # ä¿å­˜ F0 æ›²çº¿åˆ° dataset

  Phase 2: Feature Bank Construction (3-5 å¤©)

  # è®­ç»ƒæ—¶æ”¶é›† HR latent features
  class FeatureBankCollector:
      def __init__(self, max_features=100000):
          self.features = []
          self.max_features = max_features

      def collect(self, hr_latent, lr_latent):
          if len(self.features) < self.max_features:
              self.features.append({
                  'hr': hr_latent.detach().cpu(),
                  'lr': lr_latent.detach().cpu()
              })

      def build_faiss_index(self):
          # æ„å»º FAISS ç´¢å¼•ç”¨äºå¿«é€Ÿæ£€ç´¢
          ...

  Phase 3: Retrieval-Enhanced Inference (5-7 å¤©)

  # æ¨ç†æ—¶å¯ç”¨æ£€ç´¢å¢å¼º
  def inference_with_retrieval(model, lr, feature_bank, index_rate=0.5):
      # 1. æ¨¡å‹ç”Ÿæˆ
      pred_hr = model.generate(lr)

      # 2. æ£€ç´¢å¢å¼º
      if index_rate > 0:
          retrieved_hr = feature_bank.retrieve(pred_hr, k=1)
          pred_hr = (1 - index_rate) * pred_hr + index_rate * retrieved_hr

      return pred_hr

  ---
  âš–ï¸ ä¼˜ç¼ºç‚¹æƒè¡¡

  âœ… ä¼˜ç‚¹æ€»ç»“

  1. éŸ³è´¨æå‡:
    - F0 å¼•å¯¼ â†’ éŸ³é«˜å‡†ç¡®ï¼Œæ³›éŸ³ç»“æ„åˆç†
    - Index Retrieval â†’ ç»†èŠ‚æ›´çœŸå®ï¼Œå‡å°‘ä¼ªå½±
  2. ç‰©ç†çº¦æŸ:
    - F0 harmonic structure â†’ ç¬¦åˆå£°å­¦åŸç†
    - Retrieval from real data â†’ ä¿è¯ç‰©ç†å¯è¡Œæ€§
  3. é²æ£’æ€§:
    - Index Rate å¯è°ƒ â†’ å¹³è¡¡ç”Ÿæˆä¸æ£€ç´¢
    - F0 stability detection â†’ è‡ªé€‚åº”å¤„ç†

  âš ï¸ æ½œåœ¨é£é™©

  1. è®¡ç®—æˆæœ¬:
    - F0 extraction: +5-10ms/sample (CREPE)
    - FAISS retrieval: +2-5ms/sample
    - æ€»æ¨ç†æ—¶é—´å¯èƒ½å¢åŠ  20-30%
  2. å­˜å‚¨æˆæœ¬:
    - Feature Bank: ~10-100GB (å–å†³äºè®­ç»ƒé›†å¤§å°)
    - F0 curves: ~100MB-1GB
  3. è¿‡æ‹Ÿåˆé£é™©:
    - é«˜ Index Rate (>0.7) å¯èƒ½å¯¼è‡´è¾“å‡ºè¿‡åº¦ä¾èµ–è®­ç»ƒé›†
    - éœ€è¦ä»”ç»†è°ƒå‚

  ---
  ğŸ“š å‚è€ƒæ–‡çŒ®

  F0 ç›¸å…³

  - https://www.researchgate.net/publication/323276357_CREPE_A_Convolutional_Representation_for_Pitch_Estimation
  - https://www.semanticscholar.org/paper/Harvest:-A-High-Performance-Fundamental-Frequency-Morise/7143d07db6e2a12d0119bcd7dd21ed9
  81072e728
  - https://arxiv.org/abs/1708.00853

  Index Rate / Retrieval ç›¸å…³

  - https://en.wikipedia.org/wiki/Retrieval-based_Voice_Conversion
  - https://github.com/RVC-Project/Retrieval-based-Voice-Conversion
  - https://gudgud96.github.io/2024/09/26/annotated-rvc/

  Audio Super-Resolution

  - https://dl.acm.org/doi/10.1145/3664647.3681486
  - https://www.researchgate.net/publication/377198063_Audio_Super-Resolution_With_Robust_Speech_Representation_Learning_of_Masked
  _Autoencoder

  ---
  ğŸ¯ æœ€ç»ˆå»ºè®®

  å¯¹äº JaT-AudioSR é¡¹ç›®:

  1. çŸ­æœŸï¼ˆç«‹å³å¯åšï¼‰:
    - âœ… åœ¨æ•°æ®é¢„å¤„ç†ä¸­æ·»åŠ  F0 æå–ï¼ˆä½¿ç”¨ librosa.pyin æˆ– torchcrepeï¼‰
    - âœ… ä½œä¸º TensorBoard ç›‘æ§æŒ‡æ ‡ï¼Œåˆ†æ F0 ä¿æŒæƒ…å†µ
  2. ä¸­æœŸï¼ˆ1-2å‘¨å®éªŒï¼‰:
    - âœ… å®ç°ç®€å•çš„ Latent Feature Retrieval with FAISS
    - âœ… ä½¿ç”¨ Index Rate = 0.3-0.5 è¿›è¡Œ A/B æµ‹è¯•
  3. é•¿æœŸï¼ˆç ”ç©¶æ–¹å‘ï¼‰:
    - âœ… F0-conditioned DiT architecture
    - âœ… Multi-scale retrieval integration
    - âœ… å‘è¡¨è®ºæ–‡ï¼š"Retrieval-Enhanced Diffusion for Audio Super-Resolution"

  å…³é”®å‚æ•°å»ºè®®:
  - Index Rate: 0.4-0.6ï¼ˆéŸ³ä¹ï¼‰ï¼Œ0.2-0.4ï¼ˆè¯­éŸ³ï¼‰
  - F0 Method: CREPEï¼ˆé«˜è´¨é‡ï¼‰æˆ– Harvestï¼ˆå¹³è¡¡ï¼‰
  - Feature Bank Size: 50k-100k samples

  è¿™äº›æŠ€æœ¯å¯ä»¥æ˜¾è‘—æå‡ JaT-AudioSR çš„éŸ³è´¨å’Œé²æ£’æ€§ï¼ğŸš€