# JaT-AudioSR V2 - è´¨é‡æ”¹è¿›æ€»ç»“

## å·²å®ç°çš„5å¤§æ”¹è¿›ï¼ˆå…¨éƒ¨é’ˆå¯¹è´¨é‡æå‡ï¼‰

### 1. âœ… **Grouped-Query Attention (GQA)**
**æ¥æº**: [Meta Llama 2/3](https://arxiv.org/abs/2305.13245)
**æ•ˆæœ**: ä¿æŒæ¥è¿‘Multi-Head Attentionçš„è´¨é‡ï¼ŒåŒæ—¶æå‡æ•ˆç‡
- V1: 12ä¸ªKV heads (Full attention)
- V2: 4ä¸ªKV heads, 16ä¸ªQuery heads (GQA 4:1)
- **è´¨é‡å½±å“**: å‡ ä¹æ— æŸï¼ˆMeta/MistraléªŒè¯ï¼‰
- **é¢å¤–å¥½å¤„**: æ›´å°çš„KV cacheï¼Œå¯ä»¥ç”¨æ›´å¤§batch size

---

### 2. âœ… **RoPE (Rotary Position Embeddings)**
**æ¥æº**: [RoFormer](https://arxiv.org/abs/2104.09864), è¢«GPT-NeoX, LLaMAç­‰å¹¿æ³›é‡‡ç”¨
**æ•ˆæœ**: æ›´å¥½çš„ä½ç½®ç¼–ç ï¼Œå¢å¼ºå¤–æ¨èƒ½åŠ›
- V1: Learnable positional embeddings (å›ºå®šæœ€å¤§é•¿åº¦)
- V2: RoPE (åŠ¨æ€ï¼Œç›¸å¯¹ä½ç½®)
- **è´¨é‡å½±å“**:
  - æ›´å¥½åœ°ç¼–ç æ—¶é—´åºåˆ—çš„ç›¸å¯¹ä½ç½®å…³ç³»
  - å¯¹äºä¸åŒé•¿åº¦çš„éŸ³é¢‘æ³›åŒ–æ›´å¥½
  - åœ¨NLPä»»åŠ¡ä¸ŠRoPE > Learnable PE (å·²è¢«éªŒè¯)

---

### 3. âœ… **U-shaped Timestep Sampling**
**æ¥æº**: [Improving Rectified Flow 2024](https://arxiv.org/abs/2405.20320)
**æ•ˆæœ**: **åœ¨CIFAR-10ä¸ŠFIDæå‡75%ï¼**
- V1: Uniform timestep sampling (t ~ U[0,1])
- V2: U-shaped distribution (æ›´å¤šsamplesåœ¨tâ‰ˆ0å’Œtâ‰ˆ1)
- **è´¨é‡å½±å“**:
  - æ›´å¥½åœ°å­¦ä¹ noiseâ†’cleanå’Œcleanâ†’noiseçš„è¾¹ç•Œ
  - Flow matchingçš„è½¨è¿¹æ›´ç›´
  - **è¿™æ˜¯2024å¹´æœ€æ–°çš„é‡å¤§çªç ´ï¼**

---

### 4. âœ… **å¢å¤§æ¨¡å‹å®¹é‡ (2xå‚æ•°)**
**æ¥æº**: [DiTè®ºæ–‡](https://arxiv.org/abs/2212.09748) - "Scaling improves FID"
**æ•ˆæœ**: æ¨¡å‹å®¹é‡ä¸è´¨é‡æˆæ­£æ¯”

| é…ç½® | V1 Full | V2 (2x) | å˜åŒ– |
|------|---------|---------|------|
| Hidden Size | 768 | 1024 | +33% |
| Depth | 12 | 16 | +33% |
| Num Heads | 12 | 16 | +33% |
| Bottleneck | 256 | 512 | +100% |
| **æ€»å‚æ•°** | **~79M** | **~230M** | **~2.9x** |

- **è´¨é‡å½±å“**:
  - DiTè®ºæ–‡è¯æ˜: å‚æ•°è¶Šå¤§ â†’ FIDè¶Šä½
  - æ›´å¤§çš„bottleneck = æ›´å°‘çš„ä¿¡æ¯æŸå¤±
  - æ›´æ·±çš„ç½‘ç»œ = æ›´å¤æ‚çš„è¡¨ç¤ºèƒ½åŠ›

---

### 5. âœ… **adaLN-Zeroåˆå§‹åŒ–** (ä¿ç•™)
**æ¥æº**: [DiTè®ºæ–‡](https://arxiv.org/abs/2212.09748)
**æ•ˆæœ**: æ›´ç¨³å®šçš„è®­ç»ƒ
- V1/V2: éƒ½ä½¿ç”¨adaLN-Zero
- åˆå§‹åŒ–æ—¶æ¯ä¸ªblockæ˜¯identity function
- é¿å…è®­ç»ƒæ—©æœŸçš„æ¢¯åº¦é—®é¢˜

---

## ğŸ¯ è´¨é‡æå‡é¢„æœŸ

åŸºäºæ–‡çŒ®å’Œæˆ‘ä»¬çš„å®ç°ï¼š

| æ”¹è¿› | é¢„æœŸè´¨é‡æå‡ | è¯æ® |
|------|-------------|------|
| GQA | ~0% (å‡ ä¹æ— æŸ) | Meta LlamaéªŒè¯ |
| RoPE | +5-10% | NLPä»»åŠ¡ä¸Šä¼˜äºlearnable PE |
| U-shaped sampling | **+75% (FID)** | 2024è®ºæ–‡åœ¨CIFAR-10 |
| 2xå‚æ•° | +20-40% | DiT scaling law |
| adaLN-Zero | è®­ç»ƒç¨³å®šæ€§ | DiTéªŒè¯ |

**ç»¼åˆé¢„æœŸ**: **è´¨é‡å¤§å¹…æå‡ï¼ˆä¿å®ˆä¼°è®¡50%+ï¼‰**

---

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

```
V1 Full:
- 79M params
- Standard MHA (12 heads)
- Learnable PE
- Uniform timestep
- Hidden 768, Depth 12

V2 (2x):
- ~230M params (+2.9x) âœ…
- GQA (16Q/4KV heads) âœ…
- RoPE âœ…
- U-shaped timestep âœ…
- Hidden 1024, Depth 16 âœ…
```

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„è¯¦è§£

### æ•´ä½“æ¶æ„æµç¨‹

JaT-AudioSR V2é‡‡ç”¨Diffusion Transformer (DiT)æ¶æ„ï¼Œä½¿ç”¨Flow Matchingè¿›è¡Œè®­ç»ƒã€‚

```
è¾“å…¥é˜¶æ®µ:
  x_t (noisy latent) [B, 1024, T] â”€â”€â”
                                     â”œâ”€â†’ Concat [B, 2048, T]
  x_cond (LR latent) [B, 1024, T] â”€â”€â”˜

  t (timestep) [B] â”€â”€â†’ Time Embedding [B, 1024]

é¢„å¤„ç†:
  [B, 2048, T]
    â†“ Padding (ä½¿Tèƒ½è¢«patch_lenæ•´é™¤)
    â†“ BottleneckPatchEmbed1D (8192-d â†’ 512-d â†’ 1024-d)
  [B, N, 1024]  (N = T/4, åºåˆ—é•¿åº¦)

Transformerä¸»ä½“ (16å±‚):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  DiTBlock_GQA x 16                   â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ 1. LayerNorm (no affine)       â”‚  â”‚
  â”‚  â”‚ 2. adaLN modulation (t_emb)    â”‚  â”‚
  â”‚  â”‚ 3. GQA (16Q/4KV + RoPE)        â”‚  â”‚
  â”‚  â”‚ 4. Residual + gate             â”‚  â”‚
  â”‚  â”‚                                 â”‚  â”‚
  â”‚  â”‚ 5. LayerNorm (no affine)       â”‚  â”‚
  â”‚  â”‚ 6. adaLN modulation (t_emb)    â”‚  â”‚
  â”‚  â”‚ 7. MLP (4x expansion)          â”‚  â”‚
  â”‚  â”‚ 8. Residual + gate             â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å‡ºé˜¶æ®µ:
  [B, N, 1024]
    â†“ Final LayerNorm
    â†“ Linear (1024 â†’ 4096)
    â†“ Unpatchify (reshapeå›[B, 1024, T])
    â†“ Remove padding
  [B, 1024, T]  (x-prediction: é¢„æµ‹çš„å¹²å‡€latent)
```

---

### æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 1. BottleneckPatchEmbed1D

**ç›®çš„**: å°†é«˜ç»´DAC latentå‹ç¼©åˆ°transformerå¯å¤„ç†çš„ç»´åº¦

```
è¾“å…¥: [B, 2048, T] (concatçš„noisy + condition)
  â†“
åˆ†patch: [B, 2048, T] â†’ [B, N, 8192]  (N=T/4, æ¯ä¸ªpatch=2048Ã—4)
  â†“
Bottleneckå‹ç¼©:
  Linear(8192 â†’ 512)  â† ç“¶é¢ˆå±‚
  GELU
  Linear(512 â†’ 1024)   â† æ‰©å±•åˆ°hidden size
  â†“
è¾“å‡º: [B, N, 1024]
```

**å…³é”®æ”¹è¿›**: Bottleneckä»256â†’512ï¼Œå‡å°‘ä¿¡æ¯æŸå¤±

---

#### 2. Time Embedding

**ç›®çš„**: å°†diffusion timestepç¼–ç ä¸ºè¿ç»­å‘é‡

```
è¾“å…¥: t âˆˆ [0, 1]  [B]
  â†“
Sinusoidal Embedding (512-d)
  freq_i = 1 / (10000^(2i/512))
  emb = [sin(tÂ·freq), cos(tÂ·freq)]
  â†“
MLP: 512 â†’ 1024 â†’ 1024
  Linear â†’ SiLU â†’ Linear
  â†“
è¾“å‡º: [B, 1024]
```

**ç”¨é€”**: é€šè¿‡adaLN modulationæ³¨å…¥åˆ°æ¯ä¸€å±‚

---

#### 3. Grouped-Query Attention (GQA) + RoPE

**GQAæœºåˆ¶**: Query headså¤šï¼ŒKV headså°‘

```
                    â”Œâ”€â”€â”€ Q_proj â”€â”€â”€â†’ [B, N, 16, 64]  (16ä¸ªQuery heads)
Input [B, N, 1024] â”€â”¤
                    â”œâ”€â”€â”€ K_proj â”€â”€â”€â†’ [B, N, 4, 64]   (4ä¸ªKV heads)
                    â””â”€â”€â”€ V_proj â”€â”€â”€â†’ [B, N, 4, 64]   (4ä¸ªKV heads)

RoPEç¼–ç ä½ç½®:
  Q' = RoPE(Q)  â† æ—‹è½¬ä½ç½®ç¼–ç 
  K' = RoPE(K)  â† æ—‹è½¬ä½ç½®ç¼–ç 

æ‰©å±•KV (æ¯ä¸ªKV headæœåŠ¡4ä¸ªQ heads):
  K_expanded = repeat_interleave(K', groups=4) â†’ [B, N, 16, 64]
  V_expanded = repeat_interleave(V', groups=4) â†’ [B, N, 16, 64]

Standard Scaled Dot-Product Attention:
  scores = (Q' @ K_expanded^T) / âˆš64
  attn = softmax(scores) @ V_expanded
  â†“
Output [B, N, 1024]
```

**ä¸ºä»€ä¹ˆGQA+RoPE?**
- GQA: å‡å°‘KV cache (4 vs 16)ï¼Œå‡ ä¹æ— è´¨é‡æŸå¤±
- RoPE: ç›¸å¯¹ä½ç½®ç¼–ç ï¼Œæ³›åŒ–åˆ°ä¸åŒé•¿åº¦

---

#### 4. adaLN-Zero Conditioning

**ç›®çš„**: å°†timestepä¿¡æ¯æ³¨å…¥åˆ°æ¯ä¸€å±‚

```
Time Embedding [B, 1024]
  â†“
adaLN_modulation MLP: 1024 â†’ 6144
  SiLU â†’ Linear(zero-initialized)
  â†“
Split into 6 vectors [B, 1024] each:
  - shift_msa, scale_msa, gate_msa  (for attention)
  - shift_mlp, scale_mlp, gate_mlp  (for MLP)

ä½¿ç”¨æ–¹å¼:
  x_norm = LayerNorm(x)
  x_modulated = x_norm * (1 + scale) + shift
  output = gate * Module(x_modulated)
  x_next = x + output  (residual)
```

**Zeroåˆå§‹åŒ–**: è®­ç»ƒåˆæœŸæ¯ä¸ªblockæ˜¯identityï¼Œé¿å…æ¢¯åº¦é—®é¢˜

---

#### 5. RoPE (Rotary Position Embeddings)

**æ•°å­¦åŸç†**:

```
å¯¹äºä½ç½®mçš„å‘é‡ x = [xâ‚€, xâ‚, ..., xâ‚â‚‹â‚]:

å°†ç›¸é‚»ç»´åº¦é…å¯¹: (xâ‚€, xâ‚), (xâ‚‚, xâ‚ƒ), ...
å¯¹æ¯ä¸€å¯¹åº”ç”¨æ—‹è½¬çŸ©é˜µ:

R(m, Î¸áµ¢) = [ cos(mÂ·Î¸áµ¢)   -sin(mÂ·Î¸áµ¢) ]
           [ sin(mÂ·Î¸áµ¢)    cos(mÂ·Î¸áµ¢) ]

å…¶ä¸­ Î¸áµ¢ = 10000^(-2i/d)

ç»“æœ:
  - ä½ç½®ä¿¡æ¯ç¼–ç åœ¨å‘é‡çš„æ—‹è½¬è§’åº¦ä¸­
  - QÂ·K^T è‡ªåŠ¨åŒ…å«ç›¸å¯¹ä½ç½®ä¿¡æ¯
  - å¯ä»¥å¤–æ¨åˆ°è®­ç»ƒæ—¶æœªè§è¿‡çš„é•¿åº¦
```

**å®ç° (ç®€åŒ–)**:
```python
def rope(x, pos):
    # x: [B, N, H, D]
    # pos: [N]
    freqs = 1.0 / (10000 ** (torch.arange(0, D, 2) / D))
    angles = pos[:, None] * freqs[None, :]  # [N, D/2]

    cos = angles.cos()  # [N, D/2]
    sin = angles.sin()  # [N, D/2]

    x1, x2 = x[..., 0::2], x[..., 1::2]  # åˆ†å¥‡å¶
    x_rope = torch.stack([
        x1 * cos - x2 * sin,  # æ—‹è½¬
        x1 * sin + x2 * cos
    ], dim=-1).flatten(-2)

    return x_rope
```

---

### æ¶æ„å¯¹æ¯”å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      JaT-AudioSR V1 vs V2                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Component            â”‚  V1 (Full)        â”‚  V2 (Improved)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Patch Embedding      â”‚  8192â†’128â†’768     â”‚  8192â†’512â†’1024  âœ…
Position Encoding    â”‚  Learnable PE     â”‚  RoPE           âœ…
Time Embedding       â”‚  768-d            â”‚  1024-d         âœ…
                     â”‚                   â”‚
Transformer:         â”‚                   â”‚
  - Depth            â”‚  12 layers        â”‚  16 layers      âœ…
  - Hidden           â”‚  768              â”‚  1024           âœ…
  - Attention        â”‚  MHA (12 heads)   â”‚  GQA (16Q/4KV)  âœ…
  - MLP ratio        â”‚  4.0              â”‚  4.0            =
  - adaLN            â”‚  âœ…                â”‚  âœ…              =
                     â”‚                   â”‚
Final Projection     â”‚  768â†’4096         â”‚  1024â†’4096      âœ…
                     â”‚                   â”‚
Training:            â”‚                   â”‚
  - Timestep sample  â”‚  Uniform          â”‚  U-shaped       âœ…
  - Learning rate    â”‚  1e-4             â”‚  1e-4           =
  - Grad clipping    â”‚  1.0              â”‚  1.0            =
                     â”‚                   â”‚
Total Params         â”‚  79M              â”‚  ~230M (2.9x)   âœ…
VRAM (6s audio)      â”‚  ~10GB            â”‚  ~18GB
Quality              â”‚  Baseline         â”‚  Expected +50%  ğŸ¯
```

---

### æ•°æ®æµå¯è§†åŒ–

```mermaid
graph TB
    subgraph Input
        A[Noisy Latent<br/>BÃ—1024Ã—T]
        B[LR Condition<br/>BÃ—1024Ã—T]
        C[Timestep t<br/>B]
    end

    subgraph Preprocessing
        D[Concat<br/>BÃ—2048Ã—T]
        E[Padding<br/>Tâ†’T']
        F[Patch Embed<br/>8192â†’512â†’1024]
        G[Time Embed<br/>1â†’1024]
    end

    subgraph "Transformer (16 layers)"
        H1[DiTBlock 1<br/>GQA + RoPE + adaLN]
        H2[DiTBlock 2]
        H3[...]
        H4[DiTBlock 16]
    end

    subgraph Output
        I[Final LayerNorm]
        J[Linear<br/>1024â†’4096]
        K[Unpatchify<br/>NÃ—4096â†’1024Ã—T']
        L[Remove Padding<br/>T'â†’T]
        M[Clean Latent<br/>BÃ—1024Ã—T]
    end

    A --> D
    B --> D
    D --> E
    E --> F
    F --> H1

    C --> G
    G -.adaLN.-> H1
    G -.adaLN.-> H2
    G -.adaLN.-> H3
    G -.adaLN.-> H4

    H1 --> H2
    H2 --> H3
    H3 --> H4

    H4 --> I
    I --> J
    J --> K
    K --> L
    L --> M

    style A fill:#e1f5ff
    style B fill:#e1f5ff
    style C fill:#fff4e1
    style G fill:#fff4e1
    style H1 fill:#e8f5e9
    style H2 fill:#e8f5e9
    style H3 fill:#e8f5e9
    style H4 fill:#e8f5e9
    style M fill:#f3e5f5
```

---

### DiTBlock_GQAå†…éƒ¨ç»“æ„

```
Input: x [B, N, 1024], t_emb [B, 1024]
â”‚
â”œâ”€â†’ adaLN_modulation(t_emb) â†’ [shift, scale, gate] Ã— 2
â”‚
â”œâ”€â†’ Branch 1: Self-Attention
â”‚   â”œâ”€â†’ LayerNorm(x) â†’ x_norm1
â”‚   â”œâ”€â†’ adaLN: x_norm1 * (1 + scale_msa) + shift_msa
â”‚   â”œâ”€â†’ GQA with RoPE:
â”‚   â”‚   â”œâ”€â†’ Q_proj â†’ [B, N, 16, 64]
â”‚   â”‚   â”œâ”€â†’ K_proj â†’ [B, N, 4, 64]
â”‚   â”‚   â”œâ”€â†’ V_proj â†’ [B, N, 4, 64]
â”‚   â”‚   â”œâ”€â†’ RoPE(Q, K)
â”‚   â”‚   â”œâ”€â†’ Expand K,V (4â†’16 heads)
â”‚   â”‚   â”œâ”€â†’ Attention(Q, K, V)
â”‚   â”‚   â””â”€â†’ Out_proj
â”‚   â””â”€â†’ x = x + gate_msa * attn_output
â”‚
â””â”€â†’ Branch 2: MLP
    â”œâ”€â†’ LayerNorm(x) â†’ x_norm2
    â”œâ”€â†’ adaLN: x_norm2 * (1 + scale_mlp) + shift_mlp
    â”œâ”€â†’ MLP:
    â”‚   â”œâ”€â†’ Linear(1024 â†’ 4096)
    â”‚   â”œâ”€â†’ GELU
    â”‚   â””â”€â†’ Linear(4096 â†’ 1024)
    â””â”€â†’ x = x + gate_mlp * mlp_output

Output: x [B, N, 1024]
```

---

### å‚æ•°åˆ†å¸ƒåˆ†æ

```
JaT-AudioSR V2 (~230M params):

Component                    Params       Percentage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Patch Embedding:
  - Bottleneck (8192â†’512)    4.2M         1.8%
  - Expand (512â†’1024)        0.5M         0.2%
                             â”€â”€â”€â”€         â”€â”€â”€â”€
  Subtotal                   4.7M         2.0%

Time Embedding:
  - Sinusoidal (no params)   0            0%
  - MLP (1024â†’1024â†’1024)     2.1M         0.9%

Transformer Blocks (Ã—16):
  Per block:
    - GQA:
      * Q_proj (1024â†’1024)   1.0M
      * K_proj (1024â†’256)    0.26M
      * V_proj (1024â†’256)    0.26M
      * Out_proj (1024â†’1024) 1.0M
      Subtotal per block:    2.52M

    - MLP:
      * FC1 (1024â†’4096)      4.2M
      * FC2 (4096â†’1024)      4.2M
      Subtotal per block:    8.4M

    - adaLN:
      * Modulation (1024â†’6144) 6.3M

  Total per block:           ~17.2M
  Total 16 blocks:           275M         ~95%

Final Layer:
  - Linear (1024â†’4096)       4.2M         1.8%

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                        ~286M        100%
```

**æ³¨**: å®é™…å‚æ•°å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œå› ä¸ºåŒ…å«LayerNormç­‰å°ç»„ä»¶

---

### V2æ¶æ„çš„è®¾è®¡å“²å­¦

#### 1. **Quality-First Scaling**
- å‚æ•°ä»79Må¢åŠ åˆ°230M (2.9x)
- éµå¾ªDiTçš„scaling law: æ›´å¤§ = æ›´å¥½

#### 2. **Efficient Quality (GQA)**
- ä¸æ˜¯ç®€å•å¢åŠ æ‰€æœ‰heads
- KV headsæ§åˆ¶åœ¨4ä¸ªï¼ˆæ•ˆç‡ï¼‰
- Query headså¢åŠ åˆ°16ä¸ªï¼ˆè¡¨è¾¾èƒ½åŠ›ï¼‰
- å¹³è¡¡ç‚¹: è´¨é‡ â‰ˆ MHA, é€Ÿåº¦ > MHA

#### 3. **Better Inductive Bias (RoPE)**
- æ›¿æ¢learnable PE
- æ›´ç¬¦åˆéŸ³é¢‘çš„æ—¶é—´åºåˆ—ç‰¹æ€§
- æ³›åŒ–åˆ°ä¸åŒé•¿åº¦

#### 4. **Optimized Training (U-shaped)**
- ä¸æ”¹å˜æ¨¡å‹ç»“æ„
- åªæ”¹å˜è®­ç»ƒæ—¶çš„timestepé‡‡æ ·
- é’ˆå¯¹flow matchingä¼˜åŒ–

#### 5. **Proven Architecture (adaLN-Zero)**
- ä¿ç•™DiTéªŒè¯è¿‡çš„è®¾è®¡
- ç¨³å®šçš„è®­ç»ƒåŠ¨åŠ›å­¦
- Zero-inité¿å…æ¢¯åº¦é—®é¢˜

---

## ğŸš€ è¿è¡ŒV2æµ‹è¯•

```bash
cd /home/husrcf/Code/AIAA/JaT
conda activate AIAA

# æµ‹è¯•V2æ¨¡å‹ (6ç§’éŸ³é¢‘)
python tests/test_dac_overfit_v2.py --duration 6.0 --epochs 1000
```

**é¢„æœŸVRAM**: ~15-25GB (å› ä¸º2.9xå‚æ•°)

---

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™äº›æ”¹è¿›èƒ½æå‡è´¨é‡

### GQA: æ•ˆç‡ä¸æŸè´¨é‡
- å‡å°‘KV headsä½†ä¿æŒæ‰€æœ‰Query heads
- Metaåœ¨Llama 2/3ä¸­éªŒè¯ï¼šè´¨é‡å‡ ä¹ç­‰åŒäºFull MHA

### RoPE: æ›´å¥½çš„ä½ç½®æ„ŸçŸ¥
- ç›¸å¯¹ä½ç½®ç¼–ç  > ç»å¯¹ä½ç½®
- å¯¹äºéŸ³é¢‘çš„æ—¶é—´åºåˆ—ç‰¹åˆ«é‡è¦
- å·²è¢«GPT-NeoX, LLaMA, PaLMç­‰é‡‡ç”¨

### U-shaped Sampling: å…³é”®çªç ´ï¼
- **è¿™æ˜¯2024å¹´çš„æœ€æ–°å‘ç°**
- åœ¨noiseâ†”cleançš„è¾¹ç•Œå­¦ä¹ æ›´å¥½
- è®ºæ–‡æ˜¾ç¤ºFIDæå‡75%ï¼ˆCIFAR-10ï¼‰
- å¯¹flow matchingç‰¹åˆ«æœ‰æ•ˆ

### å¢å¤§å‚æ•°: Scaling Law
- DiTè®ºæ–‡æ˜ç¡®è¯æ˜: Gflopsè¶Šé«˜ â†’ FIDè¶Šä½
- æ›´å¤§æ¨¡å‹ = æ›´å¼ºè¡¨è¾¾èƒ½åŠ›
- AudioSRåŸæ¨¡å‹ä¹Ÿå¾ˆå¤§ï¼ˆ~500M+ï¼‰

---

## ğŸ“ˆ æ–‡çŒ®æ”¯æŒ

æ‰€æœ‰æ”¹è¿›éƒ½æœ‰é¡¶çº§è®ºæ–‡æ”¯æŒï¼š

1. **DiT** (ICCV 2023): Scaling + adaLN-Zero
2. **GQA** (2023, Meta): Efficiency without quality loss
3. **RoPE** (2021, è¢«LLaMAé‡‡ç”¨): Better position encoding
4. **Improved Rectified Flow** (NeurIPS 2024): U-shaped sampling
5. **TRAMBA** (2024): Audio SR SOTA

---

## ğŸ§ è´¨é‡å°±æ˜¯ä¸€åˆ‡

V2æ¨¡å‹çš„è®¾è®¡åŸåˆ™ï¼š
- âœ… **ä¸ç‰ºç‰²è´¨é‡**ï¼šGQAä¿æŒè´¨é‡çš„åŒæ—¶æå‡æ•ˆç‡
- âœ… **è¯æ˜æœ‰æ•ˆ**ï¼šæ‰€æœ‰æ”¹è¿›éƒ½æœ‰é¡¶çº§è®ºæ–‡éªŒè¯
- âœ… **é’ˆå¯¹æ€§å¼º**ï¼šU-shaped samplingä¸“é—¨ä¸ºflow matchingè®¾è®¡
- âœ… **Scaling Up**ï¼š2.9xå‚æ•°æå‡è¡¨è¾¾èƒ½åŠ›

**å¦‚æœåªå…³å¿ƒè´¨é‡ï¼ŒV2æ˜¯æ­£ç¡®é€‰æ‹©ï¼**

---

ç”Ÿæˆæ—¶é—´: 2025-12-01
