<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                             â•‘
â•‘       â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•‘
â•‘       â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•‘
â•‘       â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•  â•‘
â•‘  â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•‘
â•‘  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘  â•‘
â•‘   â•šâ•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•  â•‘
â•‘                                             â•‘
â•‘    Just Audio Transformer Super Solution    â•‘
â•‘                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

# JaT-AudioSR: Audio Super-Resolution with Diffusion Transformers

ğŸµ **é«˜è´¨é‡éŸ³é¢‘è¶…åˆ†è¾¨ç‡ç³»ç»Ÿ** ğŸµ

åŸºäº Diffusion Transformer (DiT) æ¶æ„ï¼Œä½¿ç”¨ Flow Matching è®­ç»ƒèŒƒå¼å’Œ DAC ç¼–ç å™¨åœ¨æ½œç©ºé—´è¿›è¡Œç”Ÿæˆã€‚

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-Research-green.svg)](LICENSE)

</div>

## ä¸»è¦ç‰¹æ€§

- **DiT æ¶æ„**: Diffusion Transformer with Grouped-Query Attention (GQA) å’Œ RoPE ä½ç½®ç¼–ç 
- **Flow Matching**: x-prediction è®­ç»ƒæ–¹æ³•ï¼Œç›´æ¥é¢„æµ‹å¹²å‡€ä¿¡å·
- **DAC æ½œç©ºé—´**: ä½¿ç”¨ Descript Audio Codec (44.1kHz) åœ¨å‹ç¼©æ½œç©ºé—´è®­ç»ƒï¼Œæ•ˆç‡æå‡ 512x
- **Latent Perceptual Loss**: é¢‘åŸŸæ„ŸçŸ¥æŸå¤± + å¤šå°ºåº¦æŸå¤± + ä¸€è‡´æ€§çº¦æŸï¼Œæ— éœ€è§£ç å¼€é”€
- **GQA ä¼˜åŒ–**: 20 Q-heads, 4 KV-headsï¼ŒèŠ‚çœ 80% KV å‚æ•°
- **CFG æ¨ç†**: Classifier-Free Guidance æ”¯æŒå¯æ§ç”Ÿæˆè´¨é‡

## æ¶æ„è¯´æ˜

### æ¨¡å‹ç»“æ„
```
Low-Res Audio (16kHz) â†’ DAC Encoder â†’ LR Latent [B, 1024, T/512]
                                          â†“
                                    DiT Transformer (28 layers)
                                    - GQA (20Q/4KV heads)
                                    - RoPE ä½ç½®ç¼–ç 
                                    - AdaLN-Zero è°ƒåˆ¶
                                          â†“
                            HR Latent [B, 1024, T/512] â†’ DAC Decoder
                                          â†“
                                High-Res Audio (44.1kHz)
```

### è®­ç»ƒè„šæœ¬å¯¹æ¯”

| è„šæœ¬ | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | ä¸»è¦ç‰¹æ€§ | é€‚ç”¨åœºæ™¯ |
|------|--------|---------|---------|---------|
| `train_ddp_v1.py` | 60+75M | ~7GB | æå°æ¨¡å‹ï¼Œå¿«é€ŸéªŒè¯ | åŸç†éªŒè¯ |
| `train_ddp_v2.py` | 288+75M | ~13GB | å°æ¨¡å‹ï¼Œå¿«é€Ÿè®­ç»ƒ | èµ„æºå—é™ï¼Œå¿«é€Ÿå®éªŒ |
| `train_ddp_v3.py` | 766+75M | ~34GB | å¤§æ¨¡å‹ï¼Œä»… MSE loss | åŸºç¡€ baseline |
| `train_ddp_v3mod1.py` | 780+75M | ~34GB | + é¢‘åŸŸæŸå¤± + å¤šå°ºåº¦æŸå¤± | åˆæ­¥æ”¹è¿›ï¼ˆæœ‰é¢‘åŸŸ bugï¼‰ |
| **`train_ddp_v3mod2.py`** | **766M** | **~30GB** | **å®Œæ•´ Latent Perceptual Loss** | **æ¨èä½¿ç”¨** |

#### MOD2 æ ¸å¿ƒæ”¹è¿›

**train_ddp_v3mod2.py** åŒ…å«ä»¥ä¸‹å…³é”®åˆ›æ–°ï¼š

1. **Fixed Frequency-Domain Loss** (è§£å†³é‡‘å±éŸ³å’Œå™ªç‚¹)
   - å¯¹æ•°å¹…åº¦æŸå¤± `L1(log(Mag))` æ›¿ä»£çº¿æ€§æŸå¤±ï¼ˆç¬¦åˆå¬è§‰æ„ŸçŸ¥ï¼‰
   - æ™ºèƒ½ç›¸ä½çº¦æŸï¼šä»…çº¦æŸä½ 30% é¢‘ç‡ï¼ˆé¿å…é«˜é¢‘éšæœºç›¸ä½å™ªå£°ï¼‰
   - ç§»é™¤é«˜é¢‘åŠ æƒï¼ˆé˜²æ­¢è¿‡åº¦å¼ºè°ƒé«˜é¢‘å¯¼è‡´çš„å™ªç‚¹ï¼‰

2. **Hybrid Consistency Loss** (ä¿®å¤ Mel L1 æ¶åŒ–é—®é¢˜)
   - ç‰©ç†çº¦æŸï¼š`Downsample(Generated_HR) â‰ˆ Input_LR`
   - ä¸‰æ®µå¼é¢‘ç‡ç­–ç•¥ï¼š
     - ä¸¥æ ¼å¸¦ (0-0.3Fs): Complex L1ï¼ˆä¸¥æ ¼çº¦æŸï¼‰
     - è¿‡æ¸¡å¸¦ (0.3-0.36Fs): å¹…åº¦ L1 + çº¿æ€§è¡°å‡ï¼ˆå¹³æ»‘è¿‡æ¸¡ï¼‰
     - é«˜é¢‘å¸¦ (0.36-0.5Fs): æ— çº¦æŸï¼ˆå…è®¸è‡ªç”±ç”Ÿæˆï¼‰
   - çº¿æ€§è¡°å‡ mask æ¨¡æ‹ŸæŠ—æ··å æ»¤æ³¢å™¨

3. **Multi-Scale Latent Loss**
   - å¤šåˆ†è¾¨ç‡æ½œç©ºé—´ç›‘ç£ (scales: 1, 2, 4)
   - æ•è·ä¸åŒæ—¶é—´å°ºåº¦çš„ç»“æ„ä¿¡æ¯

4. **FP32 FFT å¤„ç†**
   - è§£å†³ cuFFT FP16 å¯¹é 2 çš„å¹‚æ¬¡é•¿åº¦é™åˆ¶
   - æ‰€æœ‰é¢‘åŸŸæ“ä½œå¼ºåˆ¶ `.float()` è½¬æ¢

**æ€§èƒ½æå‡é¢„æœŸ**:
- LSD: 13.08 dB â†’ **8-10 dB** (ç›®æ ‡)
- Mel L1: 4.30 dB â†’ **3.5-3.8 dB** (ä¿®å¤æ¶åŒ–)
- Mel L2: 5.80 dB â†’ **æŒç»­æ”¹è¿›**
- é‡‘å±éŸ³ã€é«˜é¢‘å™ªç‚¹å®Œå…¨æ¶ˆé™¤

## å®‰è£…ä¾èµ–

### ç¯å¢ƒè¦æ±‚
- Python >= 3.9
- PyTorch >= 2.0
- CUDA >= 11.8 (æ¨è 12.1)
- æ˜¾å¡: 2Ã— RTX 4090 (24GB) æˆ– 2Ã— A100 (40GB+)

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/HUSRCF/JaTSR-Just-audio-transformer-super-solution.git
cd JaTSR-Just-audio-transformer-super-solution

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n audiosr python=3.10
conda activate audiosr

# å®‰è£… PyTorch (è¯·æ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬è°ƒæ•´)
# CUDA 12.1
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
# pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

**æ³¨æ„**: å¦‚æœä½ æ²¡æœ‰ CUDAï¼Œå¯ä»¥å®‰è£… CPU ç‰ˆæœ¬:
```bash
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

## æ•°æ®å‡†å¤‡

### 1. å‡†å¤‡æºéŸ³é¢‘
å°†é«˜è´¨é‡éŸ³é¢‘ (44.1kHz, FLAC/WAV) æ”¾å…¥ `1_source_audio/` ç›®å½•ã€‚

### 2. æ•°æ®é¢„å¤„ç†

```bash
# ä½¿ç”¨ v5 é¢„å¤„ç†è„šæœ¬ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
python prepare_dataset_v5.py
```

é¢„å¤„ç†æ­¥éª¤ï¼š
- è‡ªåŠ¨é‡é‡‡æ ·è‡³ 44.1kHz
- ç”Ÿæˆ 16kHz ä½åˆ†è¾¨ç‡å¯¹ï¼ˆLow-Pass + Downsamplingï¼‰
- DAC ç¼–ç è‡³æ½œç©ºé—´ (1024 channels, T/512 compression)
- è®¡ç®—å…¨å±€å½’ä¸€åŒ–ç»Ÿè®¡é‡
- åˆ†å‰² train/val é›†ï¼ˆ90/10ï¼‰

è¾“å‡ºç›®å½•ï¼š`data_processed_v13_final/`

## è®­ç»ƒ

### å¿«é€Ÿå¼€å§‹ï¼ˆæ¨è MOD2ï¼‰

```bash
# åŒå¡ DDP è®­ç»ƒ (æ¨è)
CUDA_VISIBLE_DEVICES=0,1 torchrun \
    --nproc_per_node=2 \
    --master_port=29500 \
    train_ddp_v3mod2.py

# å•å¡è®­ç»ƒï¼ˆè°ƒè¯•ç”¨ï¼‰
python train_ddp_v3mod2.py
```

### è®­ç»ƒé…ç½®å‚æ•°

å…³é”®è¶…å‚æ•°ï¼ˆåœ¨è„šæœ¬ä¸­ä¿®æ”¹ï¼‰ï¼š

```python
# æ¨¡å‹é…ç½®
hidden_size = 1280        # v3mod2: 1280, v2: 1024
depth = 28                # v3mod2: 28, v2: 16
num_q_heads = 20          # Query heads
num_kv_heads = 4          # KV heads (GQA)

# è®­ç»ƒé…ç½®
batch_size = 28           # æ¯å¡ batch size
num_steps = 100000        # æ€»è®­ç»ƒæ­¥æ•°
lr = 1e-4                 # å­¦ä¹ ç‡
warmup_steps = 500        # Warmup æ­¥æ•°

# Loss æƒé‡
latent_loss_weight = 0.3  # Latent Perceptual Loss æ€»æƒé‡
freq_loss_weight = 0.5    # é¢‘åŸŸæŸå¤±æƒé‡
ms_loss_weight = 0.5      # å¤šå°ºåº¦æŸå¤±æƒé‡
consistency_weight = 0.1  # ä¸€è‡´æ€§æŸå¤±æƒé‡ï¼ˆé™ä½å› å…¶æ•°å€¼è¾ƒå¤§ï¼‰

# CFG é…ç½®
cfg_scale = 3.0           # æ¨ç†æ—¶ CFG å¼ºåº¦
classifier_free_prob = 0.1  # è®­ç»ƒæ—¶ 10% æ— æ¡ä»¶
condition_noise_ratio = 0.05  # æ¡ä»¶å™ªå£°å¢å¼º
```

### ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir runs/v3mod2_full_run --port 6006
```

å…³é”®ç›‘æ§æŒ‡æ ‡ï¼š
- `Loss/Total`: æ€»æŸå¤±
- `Loss/MSE`: MSE æŸå¤±
- `LatentPerc_FreqDomain`: é¢‘åŸŸæŸå¤±
- `LatentPerc_MultiScale`: å¤šå°ºåº¦æŸå¤±
- `LatentPerc_Consistency`: ä¸€è‡´æ€§æŸå¤±ï¼ˆä¿®å¤ Mel L1 æ¶åŒ–ï¼‰

### æ–­ç‚¹æ¢å¤

```bash
# è„šæœ¬ä¼šè‡ªåŠ¨ä»æœ€æ–° checkpoint æ¢å¤
# Checkpoint ä¿å­˜è·¯å¾„: checkpoints/v3mod2_full_run/
```

## æ¨ç†

### åŸºç¡€æ¨ç†

```bash
# ä½¿ç”¨ v3mod2 æ¨¡å‹æ¨ç†
python infer_test_v3m2.py \
    --input_audio path/to/lowres.wav \
    --output_dir inference_output \
    --checkpoint checkpoints/v3mod2_full_run/step_100000.pt \
    --cfg_scale 3.0 \
    --num_steps 50
```

### æ¨ç†å‚æ•°è¯´æ˜

- `--cfg_scale`: CFG å¼ºåº¦ (æ¨è 2.0-4.0)
  - 2.0: è‡ªç„¶ï¼Œå¯èƒ½ç•¥æ¨¡ç³Š
  - 3.0: **æ¨èå¹³è¡¡ç‚¹**
  - 4.0: æ›´æ¸…æ™°ï¼Œå¯èƒ½è¿‡å¢å¼º
- `--num_steps`: é‡‡æ ·æ­¥æ•° (æ¨è 25-50)
  - 25: å¿«é€Ÿï¼Œè´¨é‡ç•¥é™
  - **50: æ¨è**
  - 100: é«˜è´¨é‡ï¼Œé€Ÿåº¦æ…¢ 2x

### åˆ†å—å¤„ç†ï¼ˆé•¿éŸ³é¢‘ï¼‰

æ¨ç†è„šæœ¬è‡ªåŠ¨å¤„ç†é•¿éŸ³é¢‘åˆ†å—ï¼š
- Chunk size: 10 ç§’
- Overlap: 1 ç§’
- è‡ªåŠ¨äº¤å‰æ·¡åŒ–æ‹¼æ¥

## é¡¹ç›®ç»“æ„

```
JaT/
â”œâ”€â”€ train_ddp_v2.py              # å°æ¨¡å‹è®­ç»ƒè„šæœ¬ (288M)
â”œâ”€â”€ train_ddp_v3.py              # å¤§æ¨¡å‹ baseline (766M, MSE only)
â”œâ”€â”€ train_ddp_v3mod1.py          # MOD1: é¢‘åŸŸ+å¤šå°ºåº¦ (æœ‰ bug)
â”œâ”€â”€ train_ddp_v3mod2.py          # MOD2: å®Œæ•´æ”¹è¿› (æ¨è)
â”œâ”€â”€ infer_test_v2.py             # v2 æ¨ç†è„šæœ¬
â”œâ”€â”€ infer_test_v3.py             # v3 æ¨ç†è„šæœ¬
â”œâ”€â”€ infer_test_v3m2.py           # v3mod2 æ¨ç†è„šæœ¬
â”œâ”€â”€ prepare_dataset_v5.py        # æ•°æ®é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ calculate_metrics.py         # éŸ³é¢‘è´¨é‡è¯„ä¼° (LSD, Mel Loss)
â”œâ”€â”€ calculate_model_params.py    # æ¨¡å‹å‚æ•°é‡åˆ†æ
â”œâ”€â”€ compare_v2_v3_params.py      # v2 vs v3mod2 é…ç½®å¯¹æ¯”
â”œâ”€â”€ test_consistency_methods.py  # ä¸€è‡´æ€§æŸå¤±æ–¹æ³•æµ‹è¯•
â”œâ”€â”€ src/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ jat_audiosr_v2.py    # æ ¸å¿ƒæ¨¡å‹å®šä¹‰
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ prepare_dataset_*.py     # å†å²é¢„å¤„ç†è„šæœ¬
â”œâ”€â”€ data_processed_v13_final/    # é¢„å¤„ç†æ•°æ®é›†
â”œâ”€â”€ 1_source_audio/              # åŸå§‹éŸ³é¢‘
â”œâ”€â”€ checkpoints/                 # è®­ç»ƒ checkpoint
â”œâ”€â”€ runs/                        # TensorBoard æ—¥å¿—
â””â”€â”€ inference_output/            # æ¨ç†è¾“å‡º
```

## è¯„ä¼°æŒ‡æ ‡

ä½¿ç”¨ `calculate_metrics.py` è¯„ä¼°ç”ŸæˆéŸ³é¢‘è´¨é‡ï¼š

```bash
python calculate_metrics.py \
    --generated path/to/generated.wav \
    --reference path/to/reference.wav \
    --lowres path/to/lowres.wav
```

**æ ¸å¿ƒæŒ‡æ ‡**:
- **LSD (Log-Spectral Distance)**: å¯¹æ•°è°±è·ç¦»ï¼Œè¶Šä½è¶Šå¥½
  - å½“å‰: 13.08 dB
  - ç›®æ ‡: < 10 dB
- **Mel L1**: Mel è°± L1 è·ç¦»
  - å½“å‰: 4.30 dB (vs LR 4.04 dBï¼Œæ¶åŒ– -6.4%)
  - MOD2 ç›®æ ‡: 3.5-3.8 dB
- **Mel L2**: Mel è°± L2 è·ç¦»
  - å½“å‰: 5.80 dB (vs LR 7.30 dBï¼Œæ”¹è¿› +20.5%)

## æŠ€æœ¯ç»†èŠ‚

### Latent Perceptual Loss è¯¦è§£

**MOD2 å®Œæ•´æŸå¤±å‡½æ•°**:
```
L_total = L_MSE + Î»_latent Ã— (L_freq + L_ms + L_consistency)

å…¶ä¸­:
  L_freq = log_mag_loss + 0.1 Ã— low_freq_phase_loss
  L_ms   = (1/K) Ã— Î£ L1(pred_scale_k, target_scale_k)
  L_consistency = strict_loss + transition_loss
```

**æƒé‡é…ç½®**:
```python
Î»_latent = 0.3          # æ€»æ½œç©ºé—´æŸå¤±æƒé‡
freq_weight = 0.5       # é¢‘åŸŸæŸå¤±
ms_weight = 0.5         # å¤šå°ºåº¦æŸå¤±
consistency_weight = 0.1  # ä¸€è‡´æ€§æŸå¤±ï¼ˆå› æ•°å€¼å¤§ ~20 è€Œé™ä½ï¼‰
```

### ä¸ºä»€ä¹ˆ MOD2 ä¿®å¤äº†é‡‘å±éŸ³é—®é¢˜ï¼Ÿ

**é—®é¢˜æ ¹æº**:
1. çº¿æ€§å¹…åº¦æŸå¤± `L1(Mag)` å¯¹é«˜é¢‘å°è¯¯å·®è¿‡åº¦æƒ©ç½š
2. å…¨é¢‘æ®µç›¸ä½çº¦æŸåŒ…æ‹¬é«˜é¢‘éšæœºç›¸ä½å™ªå£°
3. é«˜é¢‘åŠ æƒ `high_freq_weight=2.0` è¿‡åº¦å¼ºè°ƒé«˜é¢‘

**MOD2 è§£å†³æ–¹æ¡ˆ**:
1. **å¯¹æ•°å¹…åº¦æŸå¤±**: `L1(log(Mag + eps))` ç¬¦åˆäººè€³å¯¹æ•°æ„ŸçŸ¥
2. **æ™ºèƒ½ç›¸ä½çº¦æŸ**: ä»…çº¦æŸä½ 30% é¢‘ç‡ï¼ˆé«˜é¢‘ç›¸ä½äººè€³ä¸æ•æ„Ÿï¼‰
3. **ç§»é™¤é«˜é¢‘åŠ æƒ**: é¿å…è¿‡åº¦ä¼˜åŒ–å¯¼è‡´çš„ä¼ªå½±

### ä¸ºä»€ä¹ˆéœ€è¦ Consistency Lossï¼Ÿ

**è§‚å¯Ÿåˆ°çš„é—®é¢˜**:
- Mel L1: 4.04 â†’ **4.30 dB** (æ¶åŒ– -6.4%)
- æ¨¡å‹"å¹»æƒ³"é«˜é¢‘å†…å®¹ä¸ LR è¾“å…¥ä¸ä¸€è‡´

**ç‰©ç†çº¦æŸ**:
```
Downsample(Generated_HR) â‰ˆ Input_LR
```

**å®ç°ç­–ç•¥**:
- ä¸¥æ ¼çº¦æŸä½é¢‘ (0-0.3Fs): ç¡®ä¿ä¸ LR å®Œå…¨ä¸€è‡´
- å¹³æ»‘è¿‡æ¸¡ (0.3-0.36Fs): çº¿æ€§è¡°å‡é¿å…é¢‘è°±ä¸è¿ç»­
- è‡ªç”±ç”Ÿæˆé«˜é¢‘ (0.36-0.5Fs): å…è®¸æ¨¡å‹é‡å»ºç»†èŠ‚

## å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜æº¢å‡ºæ€ä¹ˆåŠï¼Ÿ
**A**: ä½¿ç”¨ `train_ddp_v2.py` (288M, 11GB) æˆ–é™ä½ batch_sizeã€‚

### Q2: MOD1 å’Œ MOD2 çš„ä¸»è¦åŒºåˆ«ï¼Ÿ
**A**: MOD2 ä¿®å¤äº† MOD1 çš„é¢‘åŸŸæŸå¤± bugï¼ˆé‡‘å±éŸ³+å™ªç‚¹ï¼‰ï¼Œå¹¶æ–°å¢ä¸€è‡´æ€§æŸå¤±ä¿®å¤ Mel L1 æ¶åŒ–ã€‚

### Q3: æ¨èçš„ CFG scale æ˜¯å¤šå°‘ï¼Ÿ
**A**: 3.0 ä¸ºæœ€ä½³å¹³è¡¡ç‚¹ã€‚2.0 åè‡ªç„¶ä½†æ¨¡ç³Šï¼Œ4.0 æ›´æ¸…æ™°ä½†å¯èƒ½è¿‡å¢å¼ºã€‚

### Q4: ä¸ºä»€ä¹ˆ consistency_weight è¿™ä¹ˆå° (0.1)ï¼Ÿ
**A**: ä¸€è‡´æ€§æŸå¤±æ•°å€¼è¾ƒå¤§ (~20)ï¼Œæœ‰æ•ˆæƒé‡ä¸º 0.3 Ã— 0.1 = 0.03ï¼Œä¸å…¶ä»–æŸå¤±åŒé‡çº§ã€‚

### Q5: å¦‚ä½•é€‰æ‹© v2 è¿˜æ˜¯ v3mod2ï¼Ÿ
**A**:
- **v2 (288M)**: æ˜¾å¡ < 30GBï¼Œéœ€è¦å¿«é€Ÿè¿­ä»£
- **v3mod2 (766M)**: æ˜¾å¡ â‰¥ 40GBï¼Œè¿½æ±‚æœ€ä½³è´¨é‡

## å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹å·¥ä½œï¼š

### DAC (Descript Audio Codec)
```bibtex
@inproceedings{kumar2024high,
  title={High-Fidelity Audio Compression with Improved RVQGAN},
  author={Kumar, Rithesh and Seetharaman, Prem and Luebs, Alejandro and Kumar, Ishaan and Kumar, Kundan},
  booktitle={NeurIPS},
  year={2024}
}
```

### Flow Matching
```bibtex
@article{lipman2023flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matthew},
  journal={ICLR},
  year={2023}
}
```

### DiT (Diffusion Transformer)
```bibtex
@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={ICCV},
  year={2023}
}
```

## è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„å¯å‘ï¼š
- [Descript Audio Codec](https://github.com/descriptinc/descript-audio-codec)
- [DiT](https://github.com/facebookresearch/DiT)
- [AudioLDM 2](https://github.com/haoheliu/AudioLDM2)
- [AudioSR](https://github.com/haoheliu/versatile_audio_super_resolution)

## è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›ç ”ç©¶å’Œæ•™è‚²ç”¨é€”ã€‚

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ GitHub Issueã€‚

---

**æœ€åæ›´æ–°**: 2025-12-09
**æ¨èç‰ˆæœ¬**: `train_ddp_v3mod2.py` (å®Œæ•´ Latent Perceptual Loss)
