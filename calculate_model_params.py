"""
è®¡ç®— JaT-AudioSR V2 æ¨¡å‹çš„å‚æ•°é‡
"""

import torch
import sys
sys.path.append('/media/990Evo/Code/JaT')

from src.models.jat_audiosr_v2 import JaT_AudioSR_V2

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    return total_params, trainable_params

def format_params(num):
    """æ ¼å¼åŒ–å‚æ•°é‡æ˜¾ç¤º"""
    if num >= 1e9:
        return f"{num/1e9:.2f}B"
    elif num >= 1e6:
        return f"{num/1e6:.2f}M"
    elif num >= 1e3:
        return f"{num/1e3:.2f}K"
    else:
        return str(num)

def main():
    print("=" * 80)
    print("JaT-AudioSR V2 æ¨¡å‹å‚æ•°é‡åˆ†æ")
    print("=" * 80)

    # æ¨¡å‹é…ç½® (ä» train_ddp_v3mod2.py)
    config = {
        'input_channels': 1024,      # DAC latent channels
        'cond_channels': 1024,       # LR condition channels
        'patch_len': 4,
        'hidden_size': 1280,
        'depth': 28,                 # 28 DiT blocks
        'num_q_heads': 20,
        'num_kv_heads': 4,           # GQA: 4 KV heads shared by 20 Q heads
        'bottleneck_dim': 512,
        'mlp_ratio': 4.0,
        'dropout': 0.1,
        'drop_path_rate': 0.05
    }

    print("\nğŸ“‹ æ¨¡å‹é…ç½®:")
    print("-" * 80)
    for key, value in config.items():
        print(f"  {key:<20}: {value}")

    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ”¨ åˆ›å»ºæ¨¡å‹...")
    model = JaT_AudioSR_V2(**config)

    # è®¡ç®—å‚æ•°é‡
    total_params, trainable_params = count_parameters(model)

    print("\n" + "=" * 80)
    print("ğŸ“Š å‚æ•°é‡ç»Ÿè®¡")
    print("=" * 80)
    print(f"\næ€»å‚æ•°é‡:       {format_params(total_params):<10} ({total_params:,})")
    print(f"å¯è®­ç»ƒå‚æ•°:     {format_params(trainable_params):<10} ({trainable_params:,})")
    print(f"å›ºå®šå‚æ•°:       {format_params(total_params - trainable_params):<10} ({total_params - trainable_params:,})")

    # åˆ†æ¨¡å—ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ” åˆ†æ¨¡å—å‚æ•°é‡")
    print("=" * 80)

    module_params = {}
    for name, module in model.named_children():
        params = sum(p.numel() for p in module.parameters())
        module_params[name] = params
        print(f"  {name:<20}: {format_params(params):<10} ({params:,})")

    # DiT Block è¯¦ç»†åˆ†æ
    if hasattr(model, 'blocks') and len(model.blocks) > 0:
        print("\n" + "=" * 80)
        print("ğŸ§© å•ä¸ª DiT Block åˆ†æ")
        print("=" * 80)

        block = model.blocks[0]
        block_total = sum(p.numel() for p in block.parameters())
        print(f"\nå•ä¸ª Block å‚æ•°é‡: {format_params(block_total)} ({block_total:,})")
        print(f"28ä¸ª Block æ€»å‚æ•°é‡: {format_params(block_total * 28)} ({block_total * 28:,})")

        # Block å­æ¨¡å—
        for name, module in block.named_children():
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                print(f"  {name:<20}: {format_params(params):<10} ({params:,})")

    # ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ä¸å…¶ä»– SOTA æ¨¡å‹å¯¹æ¯”")
    print("=" * 80)

    comparisons = [
        ("JaT-AudioSR V2 (Ours)", total_params),
        ("DiT-XL/2 (Image)", 675e6),  # 675M
        ("Stable Diffusion 1.5", 860e6),  # 860M
        ("AudioLDM 2", 712e6),  # 712M
        ("Vocos", 13e6),  # 13M (vocoder)
        ("DAC", 73e6),  # 73M (codec)
    ]

    print()
    for name, params in comparisons:
        bar_length = int(params / 1e7)
        bar = "â–ˆ" * min(bar_length, 80)
        print(f"  {name:<30}: {format_params(params):<10} {bar}")

    # æ˜¾å­˜ä¼°ç®—
    print("\n" + "=" * 80)
    print("ğŸ’¾ æ˜¾å­˜ä¼°ç®— (å•å¡)")
    print("=" * 80)

    # FP32
    fp32_model_memory = total_params * 4 / (1024**3)  # 4 bytes per param
    fp32_grad_memory = trainable_params * 4 / (1024**3)
    fp32_optimizer_memory = trainable_params * 8 / (1024**3)  # AdamW: 2x params
    fp32_total = fp32_model_memory + fp32_grad_memory + fp32_optimizer_memory

    # FP16 (Mixed Precision)
    fp16_model_memory = total_params * 2 / (1024**3)
    fp16_grad_memory = trainable_params * 2 / (1024**3)
    fp16_optimizer_memory = trainable_params * 8 / (1024**3)  # AdamWçŠ¶æ€ä»æ˜¯FP32
    fp16_total = fp16_model_memory + fp16_grad_memory + fp16_optimizer_memory

    print(f"\nğŸ”¸ FP32 è®­ç»ƒ:")
    print(f"  æ¨¡å‹æƒé‡:         {fp32_model_memory:.2f} GB")
    print(f"  æ¢¯åº¦:             {fp32_grad_memory:.2f} GB")
    print(f"  ä¼˜åŒ–å™¨çŠ¶æ€:       {fp32_optimizer_memory:.2f} GB")
    print(f"  æ€»è®¡ (ä¸å«æ¿€æ´»å€¼): {fp32_total:.2f} GB")

    print(f"\nğŸ”¸ FP16 æ··åˆç²¾åº¦è®­ç»ƒ (å½“å‰ä½¿ç”¨):")
    print(f"  æ¨¡å‹æƒé‡:         {fp16_model_memory:.2f} GB")
    print(f"  æ¢¯åº¦:             {fp16_grad_memory:.2f} GB")
    print(f"  ä¼˜åŒ–å™¨çŠ¶æ€:       {fp16_optimizer_memory:.2f} GB")
    print(f"  æ€»è®¡ (ä¸å«æ¿€æ´»å€¼): {fp16_total:.2f} GB")

    print(f"\nğŸ’¡ å®é™…è®­ç»ƒæ˜¾å­˜ (batch_size=28, T=1378):")
    # ç²—ç•¥ä¼°ç®—ï¼šæ¿€æ´»å€¼ â‰ˆ æ¨¡å‹æƒé‡çš„ 2-3å€
    activation_memory = fp16_total * 2.5
    total_memory = fp16_total + activation_memory
    print(f"  ä¼°ç®—æ€»æ˜¾å­˜:       {total_memory:.2f} GB")
    print(f"  å»ºè®®æ˜¾å¡:         RTX 4090 (24GB) æˆ– A100 (40GB/80GB)")

    # GQA æ•ˆç‡åˆ†æ
    print("\n" + "=" * 80)
    print("âš¡ GQA (Grouped-Query Attention) æ•ˆç‡åˆ†æ")
    print("=" * 80)

    # å¦‚æœç”¨ MHA (Multi-Head Attention)
    mha_kv_heads = config['num_q_heads']  # 20
    gqa_kv_heads = config['num_kv_heads']  # 4

    # KV projection å‚æ•°é‡
    hidden_size = config['hidden_size']
    head_dim = hidden_size // config['num_q_heads']  # 1280 / 20 = 64

    kv_params_per_block_mha = 2 * hidden_size * hidden_size  # K + V projection
    kv_params_per_block_gqa = 2 * hidden_size * (gqa_kv_heads * head_dim)

    kv_saved = (kv_params_per_block_mha - kv_params_per_block_gqa) * config['depth']

    print(f"\nå¦‚æœä½¿ç”¨æ ‡å‡† MHA (20 KV heads):")
    print(f"  KV projection å‚æ•°: {format_params(kv_params_per_block_mha * config['depth'])}")

    print(f"\nå½“å‰ GQA (4 KV heads):")
    print(f"  KV projection å‚æ•°: {format_params(kv_params_per_block_gqa * config['depth'])}")

    print(f"\nèŠ‚çœå‚æ•°é‡: {format_params(kv_saved)} ({kv_saved:,})")
    print(f"èŠ‚çœæ¯”ä¾‹: {(1 - kv_params_per_block_gqa/kv_params_per_block_mha)*100:.1f}%")

    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
