"""
ç»˜åˆ¶å·²è§£ç éŸ³é¢‘çš„é¢‘è°±å›¾
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
from pathlib import Path

# é…ç½®
VALIDATION_SAMPLES_DIR = 'data_processed_v13_final/validation_samples'
OUTPUT_DIR = 'data_processed_v13_final/validation_samples'

def plot_audio_spectrum(audio_path, output_path):
    """ç»˜åˆ¶å•ä¸ªéŸ³é¢‘çš„é¢‘è°±å›¾"""

    # åŠ è½½éŸ³é¢‘
    print(f"åŠ è½½: {Path(audio_path).name}")
    audio, sr = librosa.load(audio_path, sr=48000)

    # åˆ›å»ºå›¾å½¢ï¼ˆ3ä¸ªå­å›¾ï¼‰
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    fig.suptitle(f'Audio Analysis: {Path(audio_path).stem}', fontsize=14, fontweight='bold')

    # 1. æ³¢å½¢å›¾
    print("  ç»˜åˆ¶æ³¢å½¢...")
    librosa.display.waveshow(audio, sr=sr, ax=axes[0], alpha=0.8)
    axes[0].set_title('Waveform', fontsize=12)
    axes[0].set_xlabel('Time (s)')
    axes[0].set_ylabel('Amplitude')
    axes[0].grid(True, alpha=0.3)

    # 2. é¢‘è°±å›¾ï¼ˆSpectrogramï¼‰
    print("  ç»˜åˆ¶é¢‘è°±å›¾...")
    D = librosa.stft(audio)
    D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
    img = librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='hz', ax=axes[1], cmap='viridis')
    axes[1].set_title('Spectrogram (Linear Frequency)', fontsize=12)
    axes[1].set_ylabel('Frequency (Hz)')
    axes[1].set_ylim(0, 24000)  # æ˜¾ç¤ºåˆ° 24kHz
    fig.colorbar(img, ax=axes[1], format='%+2.0f dB')

    # 3. Melé¢‘è°±å›¾
    print("  ç»˜åˆ¶ Mel é¢‘è°±å›¾...")
    S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=24000)
    S_db = librosa.power_to_db(S, ref=np.max)
    img2 = librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel', ax=axes[2], cmap='magma')
    axes[2].set_title('Mel Spectrogram', fontsize=12)
    axes[2].set_ylabel('Mel Frequency')
    fig.colorbar(img2, ax=axes[2], format='%+2.0f dB')

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    duration = len(audio) / sr
    peak = np.abs(audio).max()
    rms = np.sqrt(np.mean(audio**2))

    info_text = f'Duration: {duration:.2f}s | Peak: {peak:.4f} | RMS: {rms:.4f}'
    fig.text(0.5, 0.02, info_text, ha='center', fontsize=10,
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

    plt.tight_layout(rect=[0, 0.03, 1, 0.97])

    # ä¿å­˜
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"  âœ… ä¿å­˜åˆ°: {output_path}")
    plt.close()

    return duration, peak, rms

def main():
    print("=" * 70)
    print("ğŸµ éŸ³é¢‘é¢‘è°±åˆ†æ")
    print("=" * 70)
    print(f"éŸ³é¢‘ç›®å½•: {VALIDATION_SAMPLES_DIR}")

    if not os.path.exists(VALIDATION_SAMPLES_DIR):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {VALIDATION_SAMPLES_DIR}")
        return

    # æŸ¥æ‰¾æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    audio_files = list(Path(VALIDATION_SAMPLES_DIR).glob('*.wav'))

    if not audio_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼")
        return

    print(f"\næ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\n")

    # ç»˜åˆ¶æ¯ä¸ªéŸ³é¢‘çš„é¢‘è°±
    results = []
    for i, audio_path in enumerate(audio_files):
        print(f"[{i+1}/{len(audio_files)}] å¤„ç†: {audio_path.name}")

        output_path = os.path.join(OUTPUT_DIR, f"{audio_path.stem}_spectrum.png")

        try:
            duration, peak, rms = plot_audio_spectrum(str(audio_path), output_path)
            results.append({
                'file': audio_path.name,
                'duration': duration,
                'peak': peak,
                'rms': rms,
                'spectrum': output_path
            })
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

        print()

    # æ‰“å°æ±‡æ€»
    print("=" * 70)
    print("ğŸ“Š æ±‡æ€»")
    print("=" * 70)
    for r in results:
        print(f"\n{r['file']}")
        print(f"  æ—¶é•¿: {r['duration']:.2f}s")
        print(f"  å³°å€¼: {r['peak']:.4f}")
        print(f"  RMS:  {r['rms']:.4f}")
        print(f"  é¢‘è°±å›¾: {r['spectrum']}")

    print("\nâœ… å®Œæˆï¼")

if __name__ == '__main__':
    main()
