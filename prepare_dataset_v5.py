"""
JaT æ•°æ®é¢„å¤„ç†è„šæœ¬ V13 (å›å½’åŸºå‡†ç‰ˆ)
================================================
æ·±åº¦æ¯”å¯¹ Benchmark V6 åçš„ä¿®æ­£:
1. [ç¦ç”¨ Compile] å½»åº•ç§»é™¤ torch.compileã€‚æŠ¥é”™æ—¥å¿—æ˜ç¡®æ˜¾ç¤º TorchScript/Inductor æ˜¯ OOM çš„å…ƒå‡¶ã€‚
2. [ä¿ç•™ AMP] å¼€å¯ FP16 æ··åˆç²¾åº¦ (Benchmark V6 å…¶å®æœªå¼€ AMP é€Ÿåº¦å·²è¾¾æ ‡ï¼Œå¼€å¯åæ›´ç¨³)ã€‚
3. [æ˜¾å­˜ä¿æŠ¤] ç›¸æ¯” Benchmark V6 çš„ "å…¨é‡åŠ è½½è‡³GPU"ï¼Œæœ¬è„šæœ¬ä¿ç•™ "CPUåˆ‡ç‰‡->GPUç¼–ç " é€»è¾‘ï¼Œ
   è¿™æ˜¯ä¸ºäº†é˜²æ­¢é‡åˆ° >10åˆ†é’Ÿçš„é•¿éŸ³é¢‘æ—¶ç›´æ¥æ’‘çˆ†æ˜¾å­˜ã€‚

æ ¸å¿ƒé…ç½®:
- Batch Size: 8 (é…åˆ AMP å¾ˆå®‰å…¨)
- ç­–ç•¥: æµå¼å¤„ç† + æ˜¾å¼ GC
"""

import os

# ç¯å¢ƒå˜é‡é…ç½®ï¼šè§£å†³æ˜¾å­˜ç¢ç‰‡åŒ–
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64,garbage_collection_threshold:0.8,expandable_segments:True"

import torch
import torchaudio
import torchaudio.functional as AF
import numpy as np
from pathlib import Path
from tqdm import tqdm
import random
import json
import torch.multiprocessing as mp
import time
import math
import traceback

# DAC & AudioTools
import dac
from audiotools import AudioSignal

# ==================== âš™ï¸ é…ç½®å‚æ•° ====================
SOURCE_DIRS = [
    '1_source_audio',
    'extra_audio'
]

OUTPUT_DIR = 'data_processed_v13_final' 
TRAIN_DIR = os.path.join(OUTPUT_DIR, 'train')
VAL_DIR = os.path.join(OUTPUT_DIR, 'val')

# çŠ¶æ€ç»´æŠ¤æ–‡ä»¶
STATS_FILE = os.path.join(OUTPUT_DIR, 'running_stats.pt')
LOG_FILE = os.path.join(OUTPUT_DIR, 'processed_files.jsonl')
FINAL_STATS_JSON = os.path.join(OUTPUT_DIR, 'global_stats.json')

# éŸ³é¢‘å‚æ•°
HIGH_SR = 48000
LOW_SR = 16000

# Overlap é…ç½® (7s + 0.5s)
CHUNK_DURATION = 7.0    
OVERLAP_DURATION = 0.5  
MIN_DURATION = 1.0     

# æ€§èƒ½å‚æ•°
# æ—¢ç„¶ç¦ç”¨äº† compileï¼ŒBatch=8 æ˜¯éå¸¸å®‰å…¨çš„
DAC_BATCH_SIZE = 1     

# DAC æ¨¡å‹
DAC_MODEL_TYPE = "44khz"

# æ•°æ®åˆ’åˆ†
VAL_RATIO = 0.1
RANDOM_SEED = 42

# ==================== ğŸ› ï¸ å·¥å…·å‡½æ•° ====================

def save_jsonl(data, filepath):
    with open(filepath, 'a') as f:
        f.write(json.dumps(data, ensure_ascii=False) + '\n')

def load_processed_files(filepath):
    processed = set()
    if not os.path.exists(filepath):
        return processed
    print(f"ğŸ“‚ è¯»å–å¤„ç†æ—¥å¿—: {filepath}")
    with open(filepath, 'r') as f:
        for line in f:
            try:
                line = line.strip()
                if not line: continue
                data = json.loads(line)
                if data.get('status') == 'done':
                    processed.add(data['path'])
            except Exception:
                pass
    return processed

# ==================== ğŸ—ï¸ GPU Worker (æ—  Compile çº¯å‡€ç‰ˆ) ====================

def gpu_worker(gpu_id, input_queue, result_queue, output_dirs):
    try:
        # 1. åˆå§‹åŒ–
        device = f'cuda:{gpu_id}'
        torch.cuda.set_device(device)
        torch.set_float32_matmul_precision('high')
        
        print(f"ğŸš€ [GPU {gpu_id}] Worker å°±ç»ª (Mode: Streaming | No Compile)")

        # 2. åŠ è½½æ¨¡å‹
        model_path = str(dac.utils.download(model_type=DAC_MODEL_TYPE))
        dac_model = dac.DAC.load(model_path)
        dac_model = dac_model.to(device)
        dac_model.eval()
        
        # âŒ [æ˜¾å¼ç¦ç”¨] ç»ä¸ä½¿ç”¨ torch.compile
        # dac_model = torch.compile(dac_model) 
        
        # 3. å¾ªç¯å¤„ç†
        while True:
            task = input_queue.get()
            if task is None: break
            
            filepath, split_type = task
            filename = Path(filepath).stem
            save_dir = output_dirs[split_type]
            save_path = os.path.join(save_dir, f"{filename}.pt")
            
            try:
                # --- A. CPU åŠ è½½ä¸é¢„å¤„ç† ---
                # ä¿æŒéŸ³é¢‘åœ¨ CPUï¼Œé˜²æ­¢é•¿éŸ³é¢‘æ’‘çˆ† GPU
                audio, sr = torchaudio.load(filepath) 
                
                if audio.shape[0] > 1: audio = audio.mean(dim=0, keepdim=True)
                peak = audio.abs().max()
                if peak > 1.0: audio = audio / peak
                
                total_samples_original = audio.shape[1]
                duration_sec = total_samples_original / sr
                
                if duration_sec < MIN_DURATION:
                    result_queue.put(('skipped', filepath, "too_short"))
                    continue

                # --- B. CPU åˆ‡åˆ†é€»è¾‘ (Overlap) ---
                chunks_raw_cpu = []
                chunk_valid_sec = CHUNK_DURATION
                overlap_sec = OVERLAP_DURATION
                num_chunks = math.ceil(duration_sec / chunk_valid_sec)
                
                for i in range(num_chunks):
                    t_start = i * chunk_valid_sec - overlap_sec
                    t_end = t_start + chunk_valid_sec + (2 * overlap_sec)
                    
                    idx_start = int(t_start * sr)
                    idx_end = int(t_end * sr)
                    
                    pad_left = 0
                    if idx_start < 0:
                        pad_left = -idx_start
                        idx_start = 0
                    
                    pad_right = 0
                    if idx_end > total_samples_original:
                        pad_right = idx_end - total_samples_original
                        idx_end = total_samples_original
                    
                    chunk = audio[:, idx_start:idx_end]
                    
                    if pad_left > 0 or pad_right > 0:
                        chunk = torch.nn.functional.pad(chunk, (pad_left, pad_right))
                    
                    chunks_raw_cpu.append(chunk)

                # --- C. GPU æµå¼å¤„ç† (Batch Loop) ---
                latents_hr_trimmed = []
                latents_lr_trimmed = []
                hop_length_48k = None 
                
                # æ˜¾å­˜æ¸…ç†ï¼šæ¯é¦–æ­Œå¼€å§‹å‰æ¸…ç†ä¸€æ¬¡è¶³å¤Ÿäº†
                torch.cuda.empty_cache()

                for i in range(0, len(chunks_raw_cpu), DAC_BATCH_SIZE):
                    # 1. å‡†å¤‡ Batch (CPU -> GPU)
                    batch_cpu_list = chunks_raw_cpu[i : i + DAC_BATCH_SIZE]
                    
                    # é•¿åº¦å¯¹é½æ£€æŸ¥
                    target_len = batch_cpu_list[0].shape[-1]
                    clean_batch_list = []
                    for c in batch_cpu_list:
                        if c.shape[-1] != target_len:
                            diff = target_len - c.shape[-1]
                            c = torch.nn.functional.pad(c, (0, diff))
                        clean_batch_list.append(c)
                        
                    batch_raw = torch.stack(clean_batch_list)
                    # âš¡ï¸ ç§»åŠ¨åˆ° GPU
                    batch_raw = batch_raw.to(device, non_blocking=True)
                    
                    # 2. GPU é‡é‡‡æ · (Batch Level)
                    if sr != HIGH_SR:
                        batch_hr = AF.resample(batch_raw, orig_freq=sr, new_freq=HIGH_SR)
                    else:
                        batch_hr = batch_raw
                        
                    # 3. LR æ¨¡æ‹Ÿ
                    batch_lr = AF.resample(AF.resample(batch_hr, HIGH_SR, LOW_SR), LOW_SR, HIGH_SR)
                    if batch_lr.shape[-1] != batch_hr.shape[-1]:
                        batch_lr = torch.nn.functional.pad(batch_lr, (0, batch_hr.shape[-1] - batch_lr.shape[-1]))

                    # 4. AMP ç¼–ç  (æ—  Compile)
                    with torch.autocast(device_type="cuda", dtype=torch.float16):
                        def encode_helper(wav):
                            signal = AudioSignal(wav, sample_rate=HIGH_SR)
                            if dac_model.sample_rate != HIGH_SR:
                                signal = signal.resample(dac_model.sample_rate)
                            # æ™®é€šæ¨ç†
                            with torch.no_grad():
                                z, _, _, _, _ = dac_model.encode(signal.audio_data)
                            return z

                        z_hr = encode_helper(batch_hr)
                        z_lr = encode_helper(batch_lr)
                    
                    # 5. Trim å‚æ•°è®¡ç®—
                    if hop_length_48k is None:
                        hop_length_48k = batch_hr.shape[-1] / z_hr.shape[-1]
                        overlap_samples_48k = int(OVERLAP_DURATION * HIGH_SR)
                        valid_samples_48k = int(CHUNK_DURATION * HIGH_SR)
                        trim_frames = int(overlap_samples_48k / hop_length_48k)
                        valid_frames_latent = int(valid_samples_48k / hop_length_48k)

                    # 6. Trim & Collect
                    z_hr_valid = z_hr[..., trim_frames : trim_frames + valid_frames_latent]
                    z_lr_valid = z_lr[..., trim_frames : trim_frames + valid_frames_latent]
                    
                    for b in range(z_hr_valid.shape[0]):
                        latents_hr_trimmed.append(z_hr_valid[b].cpu())
                        latents_lr_trimmed.append(z_lr_valid[b].cpu())
                        
                    # âš¡ï¸ æ˜¾å¼é‡Šæ”¾æ˜¾å­˜ (é˜²æ­¢å¾ªç¯å¼•ç”¨)
                    del batch_raw, batch_hr, batch_lr, z_hr, z_lr

                # --- D. æ‹¼æ¥ ---
                full_hr = torch.cat(latents_hr_trimmed, dim=-1)
                full_lr = torch.cat(latents_lr_trimmed, dim=-1)
                
                total_samples_48k = int(duration_sec * HIGH_SR)
                expected_frames = int(total_samples_48k / hop_length_48k)
                
                full_hr = full_hr[..., :expected_frames]
                full_lr = full_lr[..., :expected_frames]

                # --- E. ç»Ÿè®¡ä¸ä¿å­˜ ---
                f_sum = full_hr.double().sum(dim=1) + full_lr.double().sum(dim=1)
                f_sq_sum = (full_hr.double()**2).sum(dim=1) + (full_lr.double()**2).sum(dim=1)
                f_count = full_hr.shape[1] + full_lr.shape[1]

                torch.save({
                    'hr_latent': full_hr.half(),
                    'lr_latent': full_lr.half(),
                    'metadata': {
                        'name': filename,
                        'path': filepath,
                        'duration': duration_sec,
                        'sr': sr
                    }
                }, save_path)

                result_queue.put(('success', filepath, (f_sum, f_sq_sum, f_count)))

            except Exception as e:
                if "out of memory" in str(e).lower():
                    print(f"âš ï¸ [GPU {gpu_id}] OOM detected. File: {filename}")
                    # å¦‚æœè¿˜æ˜¯ OOMï¼Œå¯èƒ½æ˜¯æä¸ªåˆ«åæ•°æ®ï¼Œå°è¯•æ¸…ç†åç»§ç»­
                    torch.cuda.empty_cache()
                result_queue.put(('error', filepath, str(e)))

    except Exception as e:
        print(f"ğŸ”¥ [GPU {gpu_id}] å´©æºƒ: {e}")
        traceback.print_exc()

# ==================== ğŸ§  ä¸»æ§æµç¨‹ ====================

def main():
    try: mp.set_start_method('spawn', force=True)
    except: pass
    
    print("=" * 60)
    print("ğŸš€ JaT æ•°æ®é¢„å¤„ç† V13 (å›å½’åŸºå‡†ç‰ˆ)")
    print(f"âš™ï¸  Config: Compile=OFF | Streaming=ON | Batch={DAC_BATCH_SIZE}")
    print("=" * 60)

    os.makedirs(TRAIN_DIR, exist_ok=True)
    os.makedirs(VAL_DIR, exist_ok=True)

    print("ğŸ” æ‰«æéŸ³é¢‘æ–‡ä»¶...")
    all_files = []
    for d in SOURCE_DIRS:
        if os.path.exists(d):
            all_files.extend([str(p) for p in Path(d).rglob('*') if p.suffix.lower() in ['.wav', '.flac', '.mp3']])
    
    random.seed(RANDOM_SEED)
    random.shuffle(all_files)
    
    split_idx = int(len(all_files) * (1 - VAL_RATIO))
    train_files = all_files[:split_idx]
    val_files = all_files[split_idx:]
    
    tasks = [(f, 'train') for f in train_files] + [(f, 'val') for f in val_files]
    print(f"ğŸ“‚ æ€»æ–‡ä»¶æ•°: {len(tasks)}")

    processed_set = load_processed_files(LOG_FILE)
    tasks_to_do = [t for t in tasks if t[0] not in processed_set]
    print(f"âš¡ï¸ å¾…å¤„ç†: {len(tasks_to_do)}")
    
    if not tasks_to_do:
        print("âœ… å®Œæˆã€‚")
    
    if os.path.exists(STATS_FILE):
        stats_data = torch.load(STATS_FILE)
        global_sum = stats_data['sum']
        global_sq_sum = stats_data['sq_sum']
        global_count = stats_data['count']
    else:
        global_sum = torch.zeros(1024, dtype=torch.float64)
        global_sq_sum = torch.zeros(1024, dtype=torch.float64)
        global_count = 0

    if tasks_to_do:
        num_gpus = torch.cuda.device_count()
        manager = mp.Manager()
        input_queue = manager.Queue()
        result_queue = manager.Queue()
        
        for t in tasks_to_do: input_queue.put(t)
        for _ in range(num_gpus): input_queue.put(None)

        workers = []
        output_dirs = {'train': TRAIN_DIR, 'val': VAL_DIR}
        
        for i in range(num_gpus):
            p = mp.Process(target=gpu_worker, args=(i, input_queue, result_queue, output_dirs))
            p.start()
            workers.append(p)
        
        pbar = tqdm(total=len(tasks_to_do), desc="Processing", unit="song")
        completed_curr = 0
        
        try:
            while completed_curr < len(tasks_to_do):
                if result_queue.empty():
                    if all(not p.is_alive() for p in workers): break
                    time.sleep(0.1)
                    continue
                
                res = result_queue.get()
                status, filepath, data = res
                
                if status == 'success':
                    f_sum, f_sq_sum, f_count = data
                    global_sum += f_sum
                    global_sq_sum += f_sq_sum
                    global_count += f_count
                    save_jsonl({'path': filepath, 'status': 'done'}, LOG_FILE)
                    completed_curr += 1
                    pbar.update(1)
                    if completed_curr % 50 == 0:
                        torch.save({'sum': global_sum, 'sq_sum': global_sq_sum, 'count': global_count}, STATS_FILE)
                elif status == 'skipped':
                    save_jsonl({'path': filepath, 'status': 'skipped', 'reason': data}, LOG_FILE)
                    completed_curr += 1
                    pbar.update(1)
                elif status == 'error':
                    save_jsonl({'path': filepath, 'status': 'error', 'msg': data}, LOG_FILE)
                    completed_curr += 1
                    pbar.update(1)
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
            for p in workers: p.terminate()
        finally:
            pbar.close()
            for p in workers: 
                if p.is_alive(): p.join()
            torch.save({'sum': global_sum, 'sq_sum': global_sq_sum, 'count': global_count}, STATS_FILE)

    print("\nğŸ“Š è®¡ç®—å…¨å±€ç»Ÿè®¡é‡...")
    if global_count > 0:
        mean = global_sum / float(global_count)
        var = (global_sq_sum / float(global_count)) - (mean ** 2)
        std = torch.sqrt(torch.clamp(var, min=1e-6))
        
        final_stats = {
            'hr_mean': mean.float().tolist(),
            'hr_std': std.float().tolist(),
            'lr_mean': mean.float().tolist(),
            'lr_std': std.float().tolist(),
            'total_frames': int(global_count)
        }
        with open(FINAL_STATS_JSON, 'w') as f:
            json.dump(final_stats, f, indent=4)
        print(f"âœ… å®Œæˆ: {FINAL_STATS_JSON}")

if __name__ == '__main__':
    main()