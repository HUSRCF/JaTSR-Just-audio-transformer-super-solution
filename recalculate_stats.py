"""
é‡æ–°è®¡ç®—åˆ†ç¦»çš„ HR å’Œ LR ç»Ÿè®¡é‡
ä»å·²æœ‰çš„ .pt æ–‡ä»¶è¯»å–ï¼Œä¸é‡æ–°ç¼–ç éŸ³é¢‘
ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿ I/O
"""

import os
import json
import torch
from pathlib import Path
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# é…ç½®
DATA_DIR = 'data_processed_v13_final'
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
VAL_DIR = os.path.join(DATA_DIR, 'val')
OUTPUT_JSON = os.path.join(DATA_DIR, 'global_stats_separated.json')
NUM_WORKERS = 64  # å¤šçº¿ç¨‹æ•°é‡

def process_single_file(filepath):
    """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›ç»Ÿè®¡é‡"""
    try:
        # åŠ è½½æ•°æ®
        data = torch.load(filepath, map_location='cpu')

        hr = data['hr_latent'].float()  # [1024, T]
        lr = data['lr_latent'].float()  # [1024, T]

        # è®¡ç®—ç»Ÿè®¡
        hr_sum = hr.double().sum(dim=1)
        hr_sq_sum = (hr.double() ** 2).sum(dim=1)
        hr_count = hr.shape[1]

        lr_sum = lr.double().sum(dim=1)
        lr_sq_sum = (lr.double() ** 2).sum(dim=1)
        lr_count = lr.shape[1]

        return ('success', hr_sum, hr_sq_sum, hr_count, lr_sum, lr_sq_sum, lr_count)

    except Exception as e:
        return ('error', str(filepath), str(e))

def main():
    print("=" * 60)
    print("ğŸ”„ é‡æ–°è®¡ç®—åˆ†ç¦»çš„ HR/LR ç»Ÿè®¡é‡ (å¤šçº¿ç¨‹)")
    print("=" * 60)

    # æ”¶é›†æ‰€æœ‰ .pt æ–‡ä»¶
    all_files = []
    for split_dir in [TRAIN_DIR, VAL_DIR]:
        if os.path.exists(split_dir):
            files = list(Path(split_dir).glob("*.pt"))
            all_files.extend(files)
            print(f"ğŸ“‚ {split_dir}: {len(files)} files")

    print(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {len(all_files)}")
    print(f"ğŸ”§ çº¿ç¨‹æ•°: {NUM_WORKERS}")

    # åˆå§‹åŒ–ç´¯åŠ å™¨ï¼ˆåˆ†ç¦»çš„ HR å’Œ LRï¼‰
    hr_sum = torch.zeros(1024, dtype=torch.float64)
    hr_sq_sum = torch.zeros(1024, dtype=torch.float64)
    hr_count = 0

    lr_sum = torch.zeros(1024, dtype=torch.float64)
    lr_sq_sum = torch.zeros(1024, dtype=torch.float64)
    lr_count = 0

    # çº¿ç¨‹é”ï¼ˆç”¨äºç´¯åŠ ï¼‰
    lock = threading.Lock()

    print("\nğŸ”¢ å¼€å§‹è®¡ç®—...")

    # å¤šçº¿ç¨‹å¤„ç†
    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {executor.submit(process_single_file, f): f for f in all_files}

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        for future in tqdm(as_completed(futures), total=len(all_files), desc="Processing"):
            result = future.result()

            if result[0] == 'success':
                _, hr_s, hr_sq_s, hr_c, lr_s, lr_sq_s, lr_c = result

                # çº¿ç¨‹å®‰å…¨ç´¯åŠ 
                with lock:
                    hr_sum += hr_s
                    hr_sq_sum += hr_sq_s
                    hr_count += hr_c

                    lr_sum += lr_s
                    lr_sq_sum += lr_sq_s
                    lr_count += lr_c
            else:
                _, filepath, error = result
                print(f"\nâš ï¸ è·³è¿‡æ–‡ä»¶ {Path(filepath).name}: {error}")

    print("\nğŸ“ è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®...")

    # HR ç»Ÿè®¡é‡
    hr_mean = hr_sum / float(hr_count)
    hr_var = (hr_sq_sum / float(hr_count)) - (hr_mean ** 2)
    hr_std = torch.sqrt(torch.clamp(hr_var, min=1e-6))

    # LR ç»Ÿè®¡é‡
    lr_mean = lr_sum / float(lr_count)
    lr_var = (lr_sq_sum / float(lr_count)) - (lr_mean ** 2)
    lr_std = torch.sqrt(torch.clamp(lr_var, min=1e-6))

    # ä¿å­˜
    stats = {
        'hr_mean': hr_mean.float().tolist(),
        'hr_std': hr_std.float().tolist(),
        'lr_mean': lr_mean.float().tolist(),
        'lr_std': lr_std.float().tolist(),
        'hr_total_frames': int(hr_count),
        'lr_total_frames': int(lr_count),
        'note': 'HR and LR statistics are now SEPARATED'
    }

    with open(OUTPUT_JSON, 'w') as f:
        json.dump(stats, f, indent=4)

    print(f"\nâœ… ä¿å­˜åˆ°: {OUTPUT_JSON}")

    # æ‰“å°å¯¹æ¯”
    print("\n" + "=" * 60)
    print("ğŸ“Š ç»Ÿè®¡é‡å¯¹æ¯”")
    print("=" * 60)
    print(f"HR: æ€»å¸§æ•°={hr_count}, mean[0:3]={hr_mean[:3].tolist()}, std[0:3]={hr_std[:3].tolist()}")
    print(f"LR: æ€»å¸§æ•°={lr_count}, mean[0:3]={lr_mean[:3].tolist()}, std[0:3]={lr_std[:3].tolist()}")
    print(f"\næ˜¯å¦ç›¸åŒ? mean={torch.allclose(hr_mean, lr_mean)}, std={torch.allclose(hr_std, lr_std)}")

    # åŠ è½½æ—§çš„ç»Ÿè®¡é‡å¯¹æ¯”
    old_stats_path = os.path.join(DATA_DIR, 'global_stats.json')
    if os.path.exists(old_stats_path):
        with open(old_stats_path, 'r') as f:
            old_stats = json.load(f)
        old_mean = torch.tensor(old_stats['hr_mean'])
        old_std = torch.tensor(old_stats['hr_std'])
        print("\næ—§ç»Ÿè®¡é‡ (æ··åˆ):")
        print(f"  mean[0:3]={old_mean[:3].tolist()}, std[0:3]={old_std[:3].tolist()}")

if __name__ == '__main__':
    main()
