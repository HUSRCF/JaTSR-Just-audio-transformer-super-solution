"""
éŸ³é¢‘æ•°æ®é›†é¢„å¤„ç†è„šæœ¬ V2 (æ”¹è¿›ç‰ˆ)
æ”¹è¿›:
1. è®¡ç®—å…¨å±€å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œå½’ä¸€åŒ–
2. ä¿å­˜ä¸ºé«˜æ•ˆçš„ .pt (PyTorch) æ ¼å¼
3. ä¿ç•™å®Œæ•´æ­Œæ›²ï¼Œæ¯é¦–æ­Œä¸€ä¸ªæ–‡ä»¶
4. ä¸¤é˜¶æ®µå¤„ç†: Pass 1 è®¡ç®—ç»Ÿè®¡é‡, Pass 2 è½¬æ¢å¹¶å½’ä¸€åŒ–
"""

import os
import torch
import torchaudio
import torchaudio.functional as AF
import numpy as np
from pathlib import Path
from tqdm import tqdm
import random
import json
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from functools import partial
import multiprocessing as mp
from threading import Thread, Lock
import queue
import time

# DAC
import dac
from audiotools import AudioSignal


# ==================== é…ç½®å‚æ•° ====================
SOURCE_DIRS = [
    '1_source_audio',  # FLAC æ­Œæ›²
    'extra_audio'      # WAV éŸ³é¢‘
]

OUTPUT_DIR = 'data_processed'  # æ–°çš„è¾“å‡ºç›®å½•
TRAIN_DIR = os.path.join(OUTPUT_DIR, 'train')
VAL_DIR = os.path.join(OUTPUT_DIR, 'val')

# éŸ³é¢‘å‚æ•°
HIGH_SR = 48000      # é«˜åˆ†è¾¨ç‡é‡‡æ ·ç‡ï¼ˆDAC éœ€è¦ï¼‰
LOW_SR = 16000       # ä½åˆ†è¾¨ç‡é‡‡æ ·ç‡ï¼ˆæ¨¡æ‹Ÿ MP3 è´¨é‡ï¼‰

# æ•°æ®é›†åˆ’åˆ†
VAL_RATIO = 0.1      # éªŒè¯é›†æ¯”ä¾‹
RANDOM_SEED = 42     # éšæœºç§å­

# DAC æ¨¡å‹
DAC_MODEL_TYPE = "44khz"

# å¹¶è¡Œå¤„ç†
NUM_WORKERS = 8      # CPU workers æ•°é‡ï¼ˆå……åˆ†åˆ©ç”¨64çº¿ç¨‹ï¼‰
DAC_BATCH_SIZE = 16    # DAC ç¼–ç æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯ä¸ªGPUï¼‰- æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œ24GBå¯å°è¯•32-64
FILE_BATCH_SIZE = 128 # æ–‡ä»¶æ‰¹å¤„ç†å¤§å°ï¼ˆæµå¼å¤„ç†ï¼‰
USE_MULTI_GPU = True  # æ˜¯å¦ä½¿ç”¨å¤šGPUå¹¶è¡Œ

# æ¢å¤æœºåˆ¶
PROGRESS_DIR = 'processing_progress'  # è¿›åº¦æ–‡ä»¶ç›®å½•
QUEUE_FILE = 'file_queue.json'        # å›ºå®šçš„æ–‡ä»¶å¤„ç†é˜Ÿåˆ—
PROGRESS_FILE = 'progress.json'       # è¿›åº¦è®°å½•

# å…¨å±€é”ï¼ˆç”¨äºå¤šçº¿ç¨‹è¿›åº¦æ›´æ–°ï¼‰
progress_lock = Lock()


# ==================== å·¥å…·å‡½æ•° ====================

def get_audio_files():
    """è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶"""
    audio_files = []
    for source_dir in SOURCE_DIRS:
        if not os.path.exists(source_dir):
            print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {source_dir}")
            continue

        for root, _, files in os.walk(source_dir):
            for file in files:
                if file.lower().endswith(('.wav', '.flac', '.mp3')):
                    filepath = os.path.join(root, file)
                    audio_files.append(filepath)

    # æ’åºç¡®ä¿æ¯æ¬¡è¿è¡Œé¡ºåºä¸€è‡´
    audio_files.sort()
    print(f"âœ… æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    return audio_files


def init_progress_tracking():
    """åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª"""
    os.makedirs(PROGRESS_DIR, exist_ok=True)

    queue_path = os.path.join(PROGRESS_DIR, QUEUE_FILE)
    progress_path = os.path.join(PROGRESS_DIR, PROGRESS_FILE)

    return queue_path, progress_path


def save_file_queue(audio_files, train_files, val_files, queue_path):
    """ä¿å­˜æ–‡ä»¶å¤„ç†é˜Ÿåˆ—ï¼ˆå›ºå®šé¡ºåºï¼‰"""
    queue_data = {
        'all_files': audio_files,
        'train_files': train_files,
        'val_files': val_files,
        'total_count': len(audio_files),
        'train_count': len(train_files),
        'val_count': len(val_files),
        'created_at': str(np.datetime64('now'))
    }

    with open(queue_path, 'w', encoding='utf-8') as f:
        json.dump(queue_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… ä¿å­˜æ–‡ä»¶é˜Ÿåˆ—åˆ°: {queue_path}")


def load_file_queue(queue_path):
    """åŠ è½½å·²æœ‰çš„æ–‡ä»¶å¤„ç†é˜Ÿåˆ—"""
    if not os.path.exists(queue_path):
        return None

    with open(queue_path, 'r', encoding='utf-8') as f:
        queue_data = json.load(f)

    print(f"âœ… åŠ è½½å·²æœ‰æ–‡ä»¶é˜Ÿåˆ—: {queue_data['total_count']} ä¸ªæ–‡ä»¶")
    return queue_data


def load_progress(progress_path):
    """åŠ è½½å¤„ç†è¿›åº¦"""
    if not os.path.exists(progress_path):
        return {
            'pass1_completed': False,
            'pass1_processed_files': [],
            'pass1_processed_batches': [],
            'global_stats': None,
            'pass2_train_processed': [],
            'pass2_val_processed': [],
            'pass2_train_completed': False,
            'pass2_val_completed': False,
        }

    with open(progress_path, 'r', encoding='utf-8') as f:
        progress = json.load(f)

    pass1_batches = len(progress.get('pass1_processed_batches', []))
    pass1_status = 'å®Œæˆ' if progress['pass1_completed'] else f'{pass1_batches} æ‰¹æ¬¡å·²å¤„ç†'

    pass2_train_count = len(progress.get('pass2_train_processed', []))
    pass2_train_status = 'å®Œæˆ' if progress.get('pass2_train_completed') else f'{pass2_train_count} ä¸ªæ–‡ä»¶å·²å¤„ç†'

    pass2_val_count = len(progress.get('pass2_val_processed', []))
    pass2_val_status = 'å®Œæˆ' if progress.get('pass2_val_completed') else f'{pass2_val_count} ä¸ªæ–‡ä»¶å·²å¤„ç†'

    print("âœ… åŠ è½½è¿›åº¦è®°å½•:")
    print(f"   Pass 1: {pass1_status}")
    print(f"   Pass 2 è®­ç»ƒé›†: {pass2_train_status}")
    print(f"   Pass 2 éªŒè¯é›†: {pass2_val_status}")

    return progress


def save_progress(progress, progress_path):
    """ä¿å­˜å¤„ç†è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with progress_lock:
        with open(progress_path, 'w', encoding='utf-8') as f:
            json.dump(progress, f, indent=2, ensure_ascii=False)


def update_pass1_progress(progress, progress_path, batch_idx, processed_files):
    """æ›´æ–° Pass 1 è¿›åº¦"""
    progress['pass1_processed_batches'].append(batch_idx)
    progress['pass1_processed_files'].extend(processed_files)
    save_progress(progress, progress_path)


def complete_pass1(progress, progress_path, stats):
    """æ ‡è®° Pass 1 å®Œæˆ"""
    progress['pass1_completed'] = True
    progress['global_stats'] = stats
    save_progress(progress, progress_path)
    print("âœ… Pass 1 å·²å®Œæˆå¹¶ä¿å­˜")


def update_pass2_progress(progress, progress_path, split, processed_files):
    """æ›´æ–° Pass 2 è¿›åº¦"""
    if split == 'train':
        progress['pass2_train_processed'].extend(processed_files)
    else:
        progress['pass2_val_processed'].extend(processed_files)
    save_progress(progress, progress_path)


def complete_pass2(progress, progress_path, split):
    """æ ‡è®° Pass 2 å®Œæˆ"""
    if split == 'train':
        progress['pass2_train_completed'] = True
    else:
        progress['pass2_val_completed'] = True
    save_progress(progress, progress_path)
    print(f"âœ… Pass 2 {split} å·²å®Œæˆå¹¶ä¿å­˜")


def get_available_gpus():
    """è·å–å¯ç”¨GPUåˆ—è¡¨"""
    if torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        return [f'cuda:{i}' for i in range(num_gpus)]
    return ['cpu']


def load_dac_model(device='cuda'):
    """åŠ è½½DACæ¨¡å‹"""
    model_path = dac.utils.download(model_type=DAC_MODEL_TYPE)
    model = dac.DAC.load(str(model_path))  # Convert Path to str
    model = model.to(device)
    model.eval()
    return model


def audio_to_dac_latent(audio, dac_model, device='cuda'):
    """å°†éŸ³é¢‘ç¼–ç ä¸ºDAC latent"""
    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)
    signal = AudioSignal(audio_tensor, sample_rate=48000)

    if dac_model.sample_rate != 48000:
        signal = signal.resample(dac_model.sample_rate)

    signal = signal.to(device)

    with torch.no_grad():
        z, codes, latents, commitment_loss, codebook_loss = dac_model.encode(signal.audio_data)

    return z.squeeze(0).cpu()  # [C, T] on CPU


def load_and_resample_audio(filepath):
    """
    æ­¥éª¤1: åŠ è½½éŸ³é¢‘å¹¶é‡é‡‡æ ·ï¼ˆä½¿ç”¨ torchaudioï¼Œæ›´å¿«ï¼‰
    è¿”å›: [(high_audio_numpy, low_audio_numpy, metadata), ...]
    """
    try:
        # ä½¿ç”¨ torchaudio åŠ è½½éŸ³é¢‘ï¼ˆæ›´å¿«ï¼‰
        audio, sr = torchaudio.load(filepath)

        # è½¬æ¢ä¸ºå•å£°é“ [1, T]
        if audio.shape[0] > 1:
            audio = audio.mean(dim=0, keepdim=True)

        filename = Path(filepath).stem

        # æ‰€æœ‰éŸ³é¢‘éƒ½ä¿æŒå®Œæ•´ï¼Œä¸åˆ‡åˆ†
        duration = audio.shape[1] / sr
        segment = audio.squeeze(0)  # [T]

        # 1. ç”Ÿæˆé«˜åˆ†è¾¨ç‡ç‰ˆæœ¬ï¼ˆ48kHzï¼‰- ä½¿ç”¨ torchaudio.functional.resample
        if sr != HIGH_SR:
            high_audio = AF.resample(segment, orig_freq=sr, new_freq=HIGH_SR)
        else:
            high_audio = segment

        # 2. ç”Ÿæˆä½åˆ†è¾¨ç‡ç‰ˆæœ¬ï¼ˆ16kHz â†’ 48kHzï¼‰
        low_audio = AF.resample(segment, orig_freq=sr, new_freq=LOW_SR)
        low_audio_upsampled = AF.resample(low_audio, orig_freq=LOW_SR, new_freq=HIGH_SR)

        # 3. å…ƒæ•°æ®
        metadata = {
            'name': filename,
            'source_file': str(filepath),
            'duration': duration,
        }

        # è½¬æ¢ä¸º numpyï¼ˆåç»­ DAC ç¼–ç éœ€è¦ï¼‰
        audio_pairs = [(high_audio.numpy(), low_audio_upsampled.numpy(), metadata)]

        return audio_pairs

    except Exception as e:
        print(f"  âŒ åŠ è½½å¤±è´¥: {filepath} - {str(e)}")
        return []


def batch_encode_dac(audio_list, dac_model, device):
    """
    æ­¥éª¤2: çœŸæ­£çš„æ‰¹é‡ DAC ç¼–ç ï¼ˆGPU åŠ é€Ÿï¼‰
    å°†ä¸€æ‰¹éŸ³é¢‘ pad å¹¶ stack æˆ [B, 1, T]ï¼Œä¸€æ¬¡æ€§ç¼–ç 
    """
    if len(audio_list) == 0:
        return []

    # 1. è½¬æ¢ä¸º tensor å¹¶æ‰¾åˆ°æœ€å¤§é•¿åº¦
    audio_tensors = [torch.from_numpy(audio).float() for audio in audio_list]
    max_length = max(a.shape[0] for a in audio_tensors)

    # 2. Pad åˆ°ç›¸åŒé•¿åº¦å¹¶ stack æˆ [B, 1, T]
    padded_audios = []
    original_lengths = []
    for audio_tensor in audio_tensors:
        original_lengths.append(audio_tensor.shape[0])
        if audio_tensor.shape[0] < max_length:
            pad_length = max_length - audio_tensor.shape[0]
            audio_tensor = torch.nn.functional.pad(audio_tensor, (0, pad_length))
        padded_audios.append(audio_tensor.unsqueeze(0))  # [1, T]

    # Stack: [B, 1, T]
    batch_audio = torch.stack(padded_audios, dim=0)  # [B, 1, T]

    # 3. åˆ›å»º AudioSignal å¹¶ç§»åˆ° GPU
    signal = AudioSignal(batch_audio, sample_rate=48000)
    if dac_model.sample_rate != 48000:
        signal = signal.resample(dac_model.sample_rate)
    signal = signal.to(device)

    # 4. æ‰¹é‡ç¼–ç ï¼ˆä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ª batchï¼‰
    with torch.no_grad():
        z, _, _, _, _ = dac_model.encode(signal.audio_data)  # [B, C, T']

    # 5. æ‹†åˆ†å›å•ä¸ªæ ·æœ¬ï¼ˆç§»å› CPUï¼‰
    latents = []
    for i in range(z.shape[0]):
        latent = z[i].cpu()  # [C, T']
        # æ ¹æ®åŸå§‹é•¿åº¦è£å‰ªï¼ˆDAC å‹ç¼©åçš„å¯¹åº”é•¿åº¦ï¼‰
        # DAC çš„å‹ç¼©ç‡çº¦ä¸º 512xï¼Œæ‰€ä»¥ä¸éœ€è¦ç‰¹åˆ«å¤„ç†
        latents.append(latent)

    return latents


def process_file_batch_on_gpu(file_batch, gpu_device, batch_idx, total_batches, progress, progress_path):
    """
    åœ¨æŒ‡å®šGPUä¸Šå¤„ç†ä¸€æ‰¹æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦ä¿å­˜ï¼‰
    """
    import time
    start_time = time.time()

    print(f"\n{'='*60}")
    print(f"[{gpu_device}] å¼€å§‹å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{total_batches}")
    print(f"[{gpu_device}] æ–‡ä»¶æ•°: {len(file_batch)}")
    print(f"{'='*60}")

    # æ¯ä¸ªè¿›ç¨‹åŠ è½½è‡ªå·±çš„DACæ¨¡å‹
    print(f"[{gpu_device}] åŠ è½½ DAC æ¨¡å‹...")
    dac_model = load_dac_model(gpu_device)
    print(f"[{gpu_device}] âœ… DAC æ¨¡å‹å·²åŠ è½½")

    # Step 1: å¹¶è¡ŒåŠ è½½å’Œé‡é‡‡æ ·éŸ³é¢‘
    audio_pairs_batch = []

    print(f"[{gpu_device}] åŠ è½½å¹¶é‡é‡‡æ ·éŸ³é¢‘æ–‡ä»¶...")
    load_start = time.time()

    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        results = list(tqdm(
            executor.map(load_and_resample_audio, file_batch),
            total=len(file_batch),
            desc=f"  [{gpu_device}] åŠ è½½éŸ³é¢‘",
            ncols=100
        ))

        for result in results:
            if result:
                audio_pairs_batch.extend(result)

    load_time = time.time() - load_start
    print(f"  âœ… [{gpu_device}] åŠ è½½å®Œæˆ: {len(audio_pairs_batch)} ä¸ªéŸ³é¢‘ç‰‡æ®µ (è€—æ—¶: {load_time:.1f}s)")

    # Step 2: DAC ç¼–ç 
    hr_latents_list = []
    lr_latents_list = []

    hr_audios = [pair[0] for pair in audio_pairs_batch]
    lr_audios = [pair[1] for pair in audio_pairs_batch]

    print(f"[{gpu_device}] å¼€å§‹ DAC ç¼–ç  (æ‰¹æ¬¡å¤§å°: {DAC_BATCH_SIZE})...")
    encode_start = time.time()

    for i in tqdm(range(0, len(hr_audios), DAC_BATCH_SIZE),
                  desc=f"  [{gpu_device}] DAC ç¼–ç ",
                  ncols=100):
        batch_hr = hr_audios[i:i+DAC_BATCH_SIZE]
        batch_lr = lr_audios[i:i+DAC_BATCH_SIZE]

        hr_latents = batch_encode_dac(batch_hr, dac_model, gpu_device)
        lr_latents = batch_encode_dac(batch_lr, dac_model, gpu_device)

        hr_latents_list.extend(hr_latents)
        lr_latents_list.extend(lr_latents)

    encode_time = time.time() - encode_start
    print(f"  âœ… [{gpu_device}] DAC ç¼–ç å®Œæˆ: {len(hr_latents_list)} ä¸ª latent (è€—æ—¶: {encode_time:.1f}s)")

    # æ˜¾ç¤º GPU æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available() and 'cuda' in gpu_device:
        gpu_id = int(gpu_device.split(':')[1]) if ':' in gpu_device else 0
        mem_allocated = torch.cuda.memory_allocated(gpu_id) / 1024**3
        mem_reserved = torch.cuda.memory_reserved(gpu_id) / 1024**3
        print(f"  ğŸ“Š [{gpu_device}] æ˜¾å­˜: {mem_allocated:.2f}GB å·²åˆ†é… / {mem_reserved:.2f}GB å·²ä¿ç•™")

    # ä¿å­˜è¿›åº¦
    print(f"[{gpu_device}] ä¿å­˜è¿›åº¦...")
    update_pass1_progress(progress, progress_path, batch_idx, file_batch)

    # æ¸…ç†å†…å­˜
    del audio_pairs_batch, hr_audios, lr_audios, dac_model
    import gc
    gc.collect()
    torch.cuda.empty_cache()

    total_time = time.time() - start_time
    print(f"âœ… [{gpu_device}] æ‰¹æ¬¡ {batch_idx+1}/{total_batches} å®Œæˆ!")
    print(f"   æ€»è€—æ—¶: {total_time:.1f}s | é€Ÿåº¦: {len(file_batch)/total_time:.2f} æ–‡ä»¶/ç§’")
    print(f"{'='*60}\n")

    return hr_latents_list, lr_latents_list


def compute_global_statistics_multi_gpu(all_files, devices, progress, progress_path):
    """
    Pass 1: ä½¿ç”¨å¤šGPUè®¡ç®—å…¨å±€ç»Ÿè®¡é‡ï¼ˆå¸¦æ–­ç‚¹æ¢å¤ï¼‰
    """
    print("\n" + "="*70)
    print("ğŸ“Š Pass 1: è®¡ç®—å…¨å±€ç»Ÿè®¡é‡ï¼ˆå¤šGPUå¹¶è¡Œ + æ–­ç‚¹æ¢å¤ï¼‰")
    print("="*70)
    print(f"   ä½¿ç”¨ {len(devices)} ä¸ª GPU: {devices}")
    print(f"   CPU workers: {NUM_WORKERS}")
    print(f"   æ–‡ä»¶æ‰¹æ¬¡å¤§å°: {FILE_BATCH_SIZE}")

    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if progress.get('pass1_completed'):
        print("âœ… Pass 1 å·²åœ¨ä¹‹å‰å®Œæˆï¼Œä½¿ç”¨å·²ä¿å­˜çš„ç»Ÿè®¡é‡")
        return progress['global_stats']

    hr_latents_list = []
    lr_latents_list = []

    # å·²å¤„ç†çš„æ‰¹æ¬¡
    processed_batches = set(progress.get('pass1_processed_batches', []))

    # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
    num_batches = (len(all_files) + FILE_BATCH_SIZE - 1) // FILE_BATCH_SIZE

    # å°†æ‰¹æ¬¡åˆ†é…ç»™ä¸åŒçš„GPU
    batch_idx = 0

    with ThreadPoolExecutor(max_workers=len(devices)) as executor:
        futures = []

        for batch_start in range(0, len(all_files), FILE_BATCH_SIZE):
            # è·³è¿‡å·²å¤„ç†çš„æ‰¹æ¬¡
            if batch_idx in processed_batches:
                print(f"â­ï¸  è·³è¿‡å·²å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{num_batches}")
                batch_idx += 1
                continue

            batch_end = min(batch_start + FILE_BATCH_SIZE, len(all_files))
            file_batch = all_files[batch_start:batch_end]

            # è½®æµåˆ†é…ç»™ä¸åŒçš„GPU
            gpu_device = devices[batch_idx % len(devices)]

            print(f"\næäº¤æ‰¹æ¬¡ {batch_idx+1}/{num_batches} åˆ° {gpu_device} ({len(file_batch)} ä¸ªæ–‡ä»¶)...")

            # æäº¤ä»»åŠ¡
            future = executor.submit(
                process_file_batch_on_gpu,
                file_batch,
                gpu_device,
                batch_idx,
                num_batches,
                progress,
                progress_path
            )
            futures.append(future)
            batch_idx += 1

        # æ”¶é›†ç»“æœ
        print(f"\nç­‰å¾…æ‰€æœ‰ GPU å®Œæˆ...")
        for future in as_completed(futures):
            hr_lats, lr_lats = future.result()
            hr_latents_list.extend(hr_lats)
            lr_latents_list.extend(lr_lats)

    # è®¡ç®—å…¨å±€ç»Ÿè®¡é‡
    total_segments = len(hr_latents_list)
    print(f"\nè®¡ç®—å…¨å±€å‡å€¼å’Œæ ‡å‡†å·® ({total_segments} ä¸ªç‰‡æ®µ)...")

    all_hr = torch.cat([lat.flatten() for lat in hr_latents_list])
    all_lr = torch.cat([lat.flatten() for lat in lr_latents_list])

    hr_mean = all_hr.mean().item()
    hr_std = all_hr.std().item()
    lr_mean = all_lr.mean().item()
    lr_std = all_lr.std().item()

    print(f"\nâœ… å…¨å±€ç»Ÿè®¡é‡:")
    print(f"   HR: mean={hr_mean:.6f}, std={hr_std:.6f}")
    print(f"   LR: mean={lr_mean:.6f}, std={lr_std:.6f}")
    print(f"   æ€»ç‰‡æ®µæ•°: {total_segments}")

    stats = {
        'hr_mean': hr_mean,
        'hr_std': hr_std,
        'lr_mean': lr_mean,
        'lr_std': lr_std,
        'num_samples': total_segments
    }

    # ä¿å­˜å®ŒæˆçŠ¶æ€
    complete_pass1(progress, progress_path, stats)

    return stats


def compute_global_statistics(all_files, dac_model, device, progress, progress_path):
    """
    Pass 1: è®¡ç®—å…¨å±€ç»Ÿè®¡é‡ï¼ˆå•GPUæµå¼å¤„ç† + æ–­ç‚¹æ¢å¤ï¼‰
    """
    print("\n" + "="*70)
    print("ğŸ“Š Pass 1: è®¡ç®—å…¨å±€ç»Ÿè®¡é‡ï¼ˆå•GPUæµå¼å¤„ç† + æ–­ç‚¹æ¢å¤ï¼‰")
    print("="*70)
    print(f"   ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"   CPU workers: {NUM_WORKERS}")
    print(f"   æ–‡ä»¶æ‰¹æ¬¡å¤§å°: {FILE_BATCH_SIZE}")

    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if progress.get('pass1_completed'):
        print("âœ… Pass 1 å·²åœ¨ä¹‹å‰å®Œæˆï¼Œä½¿ç”¨å·²ä¿å­˜çš„ç»Ÿè®¡é‡")
        return progress['global_stats']

    hr_latents_list = []
    lr_latents_list = []
    total_segments = 0

    # å·²å¤„ç†çš„æ‰¹æ¬¡
    processed_batches = set(progress.get('pass1_processed_batches', []))

    # åˆ†æ‰¹å¤„ç†æ–‡ä»¶ï¼ˆé™ä½å†…å­˜å ç”¨ï¼‰
    num_batches = (len(all_files) + FILE_BATCH_SIZE - 1) // FILE_BATCH_SIZE

    for batch_idx in range(num_batches):
        # è·³è¿‡å·²å¤„ç†çš„æ‰¹æ¬¡
        if batch_idx in processed_batches:
            print(f"â­ï¸  è·³è¿‡å·²å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{num_batches}")
            continue

        start_idx = batch_idx * FILE_BATCH_SIZE
        end_idx = min(start_idx + FILE_BATCH_SIZE, len(all_files))
        file_batch = all_files[start_idx:end_idx]

        print(f"\nå¤„ç†æ–‡ä»¶æ‰¹æ¬¡ {batch_idx+1}/{num_batches} ({len(file_batch)} ä¸ªæ–‡ä»¶)...")

        # Step 1: å¹¶è¡ŒåŠ è½½å’Œé‡é‡‡æ ·éŸ³é¢‘
        audio_pairs_batch = []

        with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
            results = list(tqdm(
                executor.map(load_and_resample_audio, file_batch),
                total=len(file_batch),
                desc=f"  åŠ è½½æ‰¹æ¬¡ {batch_idx+1}"
            ))

            for result in results:
                if result:
                    audio_pairs_batch.extend(result)

        print(f"  âœ… æ‰¹æ¬¡ {batch_idx+1}: {len(audio_pairs_batch)} ä¸ªç‰‡æ®µ")

        # Step 2: DAC ç¼–ç ï¼ˆæœ¬æ‰¹æ¬¡ï¼‰
        hr_audios = [pair[0] for pair in audio_pairs_batch]
        lr_audios = [pair[1] for pair in audio_pairs_batch]

        for i in tqdm(range(0, len(hr_audios), DAC_BATCH_SIZE), desc=f"  DAC ç¼–ç æ‰¹æ¬¡ {batch_idx+1}"):
            batch_hr = hr_audios[i:i+DAC_BATCH_SIZE]
            batch_lr = lr_audios[i:i+DAC_BATCH_SIZE]

            hr_latents = batch_encode_dac(batch_hr, dac_model, device)
            lr_latents = batch_encode_dac(batch_lr, dac_model, device)

            hr_latents_list.extend(hr_latents)
            lr_latents_list.extend(lr_latents)

        total_segments += len(audio_pairs_batch)

        # ä¿å­˜è¿›åº¦
        update_pass1_progress(progress, progress_path, batch_idx, file_batch)

        # æ¸…ç†å†…å­˜
        del audio_pairs_batch, hr_audios, lr_audios
        import gc
        gc.collect()

    # è®¡ç®—å…¨å±€ç»Ÿè®¡é‡
    print(f"\nè®¡ç®—å…¨å±€å‡å€¼å’Œæ ‡å‡†å·® ({total_segments} ä¸ªç‰‡æ®µ)...")

    all_hr = torch.cat([lat.flatten() for lat in hr_latents_list])
    all_lr = torch.cat([lat.flatten() for lat in lr_latents_list])

    hr_mean = all_hr.mean().item()
    hr_std = all_hr.std().item()
    lr_mean = all_lr.mean().item()
    lr_std = all_lr.std().item()

    print(f"\nâœ… å…¨å±€ç»Ÿè®¡é‡:")
    print(f"   HR: mean={hr_mean:.6f}, std={hr_std:.6f}")
    print(f"   LR: mean={lr_mean:.6f}, std={lr_std:.6f}")
    print(f"   æ€»ç‰‡æ®µæ•°: {total_segments}")

    stats = {
        'hr_mean': hr_mean,
        'hr_std': hr_std,
        'lr_mean': lr_mean,
        'lr_std': lr_std,
        'num_samples': total_segments
    }

    # ä¿å­˜å®ŒæˆçŠ¶æ€
    complete_pass1(progress, progress_path, stats)

    return stats


def process_and_save_dataset(train_files, val_files, dac_model, stats, device, progress, progress_path):
    """
    Pass 2: å¤„ç†å¹¶ä¿å­˜ä¸º .pt æ ¼å¼ï¼ˆå¤šçº¿ç¨‹ + æ–­ç‚¹æ¢å¤ï¼‰
    """
    print("\n" + "="*70)
    print("ğŸ’¾ Pass 2: è½¬æ¢å¹¶ä¿å­˜æ•°æ®")
    print("="*70)
    print(f"   ä½¿ç”¨ {NUM_WORKERS} ä¸ª CPU workers åŠ è½½éŸ³é¢‘")

    hr_mean = stats['hr_mean']
    hr_std = stats['hr_std']
    lr_mean = stats['lr_mean']
    lr_std = stats['lr_std']

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(TRAIN_DIR, exist_ok=True)
    os.makedirs(VAL_DIR, exist_ok=True)

    def save_samples(files, output_dir, split_name):
        """ä¿å­˜æ ·æœ¬åˆ°æŒ‡å®šç›®å½•ï¼ˆæµå¼å¤„ç† + æ–­ç‚¹æ¢å¤ï¼‰"""

        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if (split_name == 'è®­ç»ƒé›†' and progress.get('pass2_train_completed')) or \
           (split_name == 'éªŒè¯é›†' and progress.get('pass2_val_completed')):
            print(f"âœ… {split_name} å·²åœ¨ä¹‹å‰å®Œæˆï¼Œè·³è¿‡")
            # ç»Ÿè®¡å·²æœ‰æ–‡ä»¶
            existing_files = len([f for f in os.listdir(output_dir) if f.endswith('.pt')])
            return existing_files

        sample_count = 0
        processed_files_set = set(progress.get(f'pass2_{"train" if split_name == "è®­ç»ƒé›†" else "val"}_processed', []))

        # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
        remaining_files = [f for f in files if f not in processed_files_set]

        if len(remaining_files) < len(files):
            print(f"â­ï¸  {split_name}: è·³è¿‡ {len(files) - len(remaining_files)} ä¸ªå·²å¤„ç†æ–‡ä»¶")

        if len(remaining_files) == 0:
            print(f"âœ… {split_name} æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆ")
            complete_pass2(progress, progress_path, 'train' if split_name == 'è®­ç»ƒé›†' else 'val')
            return len([f for f in os.listdir(output_dir) if f.endswith('.pt')])

        # åˆ†æ‰¹å¤„ç†
        num_batches = (len(remaining_files) + FILE_BATCH_SIZE - 1) // FILE_BATCH_SIZE

        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç† {split_name}: {len(remaining_files)} ä¸ªæ–‡ä»¶ï¼Œåˆ† {num_batches} æ‰¹")
        print(f"{'='*60}")

        for batch_idx in range(num_batches):
            import time
            batch_start = time.time()

            start_idx = batch_idx * FILE_BATCH_SIZE
            end_idx = min(start_idx + FILE_BATCH_SIZE, len(remaining_files))
            file_batch = remaining_files[start_idx:end_idx]

            print(f"\nğŸ“¦ [{split_name}] æ‰¹æ¬¡ {batch_idx+1}/{num_batches}")
            print(f"   æ–‡ä»¶æ•°: {len(file_batch)}")
            print(f"   è¿›åº¦: {end_idx}/{len(remaining_files)} ({100*end_idx/len(remaining_files):.1f}%)")

            # Step 1: å¹¶è¡ŒåŠ è½½éŸ³é¢‘
            audio_pairs_batch = []

            print(f"   ğŸ”„ åŠ è½½éŸ³é¢‘...")
            with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
                results = list(tqdm(
                    executor.map(load_and_resample_audio, file_batch),
                    total=len(file_batch),
                    desc=f"  åŠ è½½ {split_name}"
                ))

                for result in results:
                    if result:
                        audio_pairs_batch.extend(result)

            print(f"   âœ… åŠ è½½å®Œæˆ: {len(audio_pairs_batch)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")

            # Step 2: æ‰¹é‡ DAC ç¼–ç å¹¶ä¿å­˜
            batch_processed_files = []

            print(f"   ğŸ”„ DAC ç¼–ç å¹¶ä¿å­˜...")
            saved_count = 0
            for i in tqdm(range(0, len(audio_pairs_batch), DAC_BATCH_SIZE),
                         desc=f"  ç¼–ç &ä¿å­˜",
                         ncols=100):
                batch_pairs = audio_pairs_batch[i:i+DAC_BATCH_SIZE]

                batch_hr = [pair[0] for pair in batch_pairs]
                batch_lr = [pair[1] for pair in batch_pairs]
                batch_meta = [pair[2] for pair in batch_pairs]

                # DAC ç¼–ç 
                hr_latents = batch_encode_dac(batch_hr, dac_model, device)
                lr_latents = batch_encode_dac(batch_lr, dac_model, device)

                # å½’ä¸€åŒ–å¹¶ä¿å­˜
                for hr_lat, lr_lat, metadata in zip(hr_latents, lr_latents, batch_meta):
                    hr_latent_norm = (hr_lat - hr_mean) / hr_std
                    lr_latent_norm = (lr_lat - lr_mean) / lr_std

                    sample_name = metadata['name']
                    save_path = os.path.join(output_dir, f"{sample_name}.pt")

                    torch.save({
                        'hr_latent': hr_latent_norm,
                        'lr_latent': lr_latent_norm,
                        'metadata': metadata,
                        'global_stats': {
                            'hr_mean': hr_mean,
                            'hr_std': hr_std,
                            'lr_mean': lr_mean,
                            'lr_std': lr_std
                        }
                    }, save_path)

                    sample_count += 1
                    saved_count += 1

            # è®°å½•å·²å¤„ç†çš„æºæ–‡ä»¶
            batch_processed_files.extend(file_batch)

            # æ›´æ–°è¿›åº¦
            update_pass2_progress(
                progress,
                progress_path,
                'train' if split_name == 'è®­ç»ƒé›†' else 'val',
                file_batch
            )

            # æ¸…ç†å†…å­˜
            del audio_pairs_batch
            import gc
            gc.collect()

            batch_time = time.time() - batch_start
            print(f"   âœ… æ‰¹æ¬¡å®Œæˆ: ä¿å­˜äº† {saved_count} ä¸ª .pt æ–‡ä»¶")
            print(f"   â±ï¸  è€—æ—¶: {batch_time:.1f}s | é€Ÿåº¦: {len(file_batch)/batch_time:.2f} æ–‡ä»¶/ç§’")

        # æ ‡è®°å®Œæˆ
        complete_pass2(progress, progress_path, 'train' if split_name == 'è®­ç»ƒé›†' else 'val')

        return sample_count

    # ä¿å­˜è®­ç»ƒé›†
    train_count = save_samples(train_files, TRAIN_DIR, "è®­ç»ƒé›†")

    # ä¿å­˜éªŒè¯é›†
    val_count = save_samples(val_files, VAL_DIR, "éªŒè¯é›†")

    print(f"\nâœ… ä¿å­˜å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {train_count} ä¸ªæ ·æœ¬")
    print(f"   éªŒè¯é›†: {val_count} ä¸ªæ ·æœ¬")

    return train_count, val_count


def save_dataset_info(stats, train_count, val_count):
    """ä¿å­˜æ•°æ®é›†ä¿¡æ¯"""
    info = {
        'version': '2.0',
        'dataset': {
            'train_samples': train_count,
            'val_samples': val_count,
            'total_samples': train_count + val_count
        },
        'audio_config': {
            'high_sr': HIGH_SR,
            'low_sr': LOW_SR
        },
        'dac_config': {
            'model_type': DAC_MODEL_TYPE,
            'latent_dim': 1024,
            'compression_rate': 512
        },
        'global_stats': {
            'hr_mean': stats['hr_mean'],
            'hr_std': stats['hr_std'],
            'lr_mean': stats['lr_mean'],
            'lr_std': stats['lr_std']
        }
    }

    info_path = os.path.join(OUTPUT_DIR, 'dataset_info.json')
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(info, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… æ•°æ®é›†ä¿¡æ¯ä¿å­˜åˆ°: {info_path}")


def main():
    print("=" * 70)
    print("ğŸµ éŸ³é¢‘æ•°æ®é›†é¢„å¤„ç† V2 (æ”¹è¿›ç‰ˆ - æµå¼å¤„ç† + æ–­ç‚¹æ¢å¤)")
    print("=" * 70)
    print("\næ”¹è¿›:")
    print("  1. âœ… å…¨å±€å‡å€¼/æ ‡å‡†å·®å½’ä¸€åŒ–")
    print("  2. âœ… ä¿å­˜ä¸ºé«˜æ•ˆ .pt æ ¼å¼")
    print("  3. âœ… æ¯é¦–æ­Œä¸€ä¸ªæ–‡ä»¶")
    print("  4. âœ… ä¸¤é˜¶æ®µå¤„ç† (ç»Ÿè®¡ â†’ è½¬æ¢)")
    print(f"  5. âœ… å¤šçº¿ç¨‹å¤„ç† ({NUM_WORKERS} workers)")
    print(f"  6. âœ… æµå¼å¤„ç† (æ‰¹æ¬¡å¤§å°: {FILE_BATCH_SIZE} æ–‡ä»¶)")
    print(f"  7. âœ… æ–­ç‚¹æ¢å¤ (å¯éšæ—¶ä¸­æ–­ï¼Œä¸‹æ¬¡ç»§ç»­)")
    print("=" * 70)

    # 0. åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
    queue_path, progress_path = init_progress_tracking()
    progress = load_progress(progress_path)

    # ç¡®ä¿è¿›åº¦æ–‡ä»¶å­˜åœ¨ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶åˆ›å»ºï¼‰
    if not os.path.exists(progress_path):
        save_progress(progress, progress_path)

    # æ£€æµ‹å¯ç”¨GPU
    available_gpus = get_available_gpus()
    print(f"\nå¯ç”¨è®¾å¤‡: {available_gpus}")

    if USE_MULTI_GPU and len(available_gpus) > 1:
        print(f"âœ… å¯ç”¨å¤šGPUæ¨¡å¼: {len(available_gpus)} ä¸ª GPU")
        use_multi_gpu = True
        devices = available_gpus
    else:
        print(f"ä½¿ç”¨å•GPUæ¨¡å¼: {available_gpus[0]}")
        use_multi_gpu = False
        device = available_gpus[0]

    # 1. è·å–æˆ–åŠ è½½æ–‡ä»¶é˜Ÿåˆ—
    queue_data = load_file_queue(queue_path)

    if queue_data is None:
        # é¦–æ¬¡è¿è¡Œï¼šåˆ›å»ºæ–‡ä»¶é˜Ÿåˆ—
        print("\nğŸ“ é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ–‡ä»¶å¤„ç†é˜Ÿåˆ—...")
        audio_files = get_audio_files()

        if len(audio_files) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼")
            return

        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼ˆå›ºå®šéšæœºç§å­ä¿è¯ä¸€è‡´æ€§ï¼‰
        random.seed(RANDOM_SEED)
        random.shuffle(audio_files)

        split_idx = int(len(audio_files) * (1 - VAL_RATIO))
        train_files = audio_files[:split_idx]
        val_files = audio_files[split_idx:]

        # ä¿å­˜é˜Ÿåˆ—
        save_file_queue(audio_files, train_files, val_files, queue_path)
    else:
        # ä»é˜Ÿåˆ—æ¢å¤
        print("\nğŸ“‚ ä»å·²æœ‰é˜Ÿåˆ—æ¢å¤...")
        audio_files = queue_data['all_files']
        train_files = queue_data['train_files']
        val_files = queue_data['val_files']

    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(audio_files)}")
    print(f"   è®­ç»ƒé›†: {len(train_files)} ä¸ªæ–‡ä»¶")
    print(f"   éªŒè¯é›†: {len(val_files)} ä¸ªæ–‡ä»¶")

    # 2. Pass 1: è®¡ç®—å…¨å±€ç»Ÿè®¡é‡
    if use_multi_gpu:
        stats = compute_global_statistics_multi_gpu(audio_files, devices, progress, progress_path)
    else:
        if not progress.get('pass1_completed'):
            dac_model = load_dac_model(device)
            print(f"\nâœ… DAC åŠ è½½å®Œæˆ on {device}")
        else:
            dac_model = None
        stats = compute_global_statistics(audio_files, dac_model, device, progress, progress_path)

    # 3. Pass 2: å¤„ç†å¹¶ä¿å­˜
    if use_multi_gpu:
        # TODO: å®ç°å¤šGPUçš„Pass 2
        print("\nâš ï¸  å¤šGPUæ¨¡å¼ä¸‹ï¼ŒPass 2 æš‚æ—¶ä½¿ç”¨å•GPU")
        dac_model = load_dac_model(devices[0])
        train_count, val_count = process_and_save_dataset(
            train_files, val_files, dac_model, stats, devices[0], progress, progress_path
        )
    else:
        if dac_model is None:
            dac_model = load_dac_model(device)
            print(f"\nâœ… DAC åŠ è½½å®Œæˆ on {device}")
        train_count, val_count = process_and_save_dataset(
            train_files, val_files, dac_model, stats, device, progress, progress_path
        )

    # 4. ä¿å­˜æ•°æ®é›†ä¿¡æ¯
    save_dataset_info(stats, train_count, val_count)

    # 7. æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ‰ é¢„å¤„ç†å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“¦ è¾“å‡ºç›®å½•: {OUTPUT_DIR}/")
    print(f"   â”œâ”€â”€ train/          ({train_count} ä¸ª .pt æ–‡ä»¶)")
    print(f"   â”œâ”€â”€ val/            ({val_count} ä¸ª .pt æ–‡ä»¶)")
    print(f"   â””â”€â”€ dataset_info.json")
    print(f"\nğŸ“Š æ¯ä¸ª .pt æ–‡ä»¶åŒ…å«:")
    print(f"   - hr_latent: å½’ä¸€åŒ–çš„é«˜åˆ†è¾¨ç‡ latent [C, T]")
    print(f"   - lr_latent: å½’ä¸€åŒ–çš„ä½åˆ†è¾¨ç‡ latent [C, T]")
    print(f"   - metadata: æ–‡ä»¶å…ƒä¿¡æ¯")
    print(f"   - global_stats: å…¨å±€ç»Ÿè®¡é‡ (ç”¨äºåå½’ä¸€åŒ–)")
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   data = torch.load('data_processed/train/song_001.pt')")
    print("   hr_latent = data['hr_latent']  # å·²å½’ä¸€åŒ–")
    print("   lr_latent = data['lr_latent']  # å·²å½’ä¸€åŒ–")
    print("=" * 70)


if __name__ == '__main__':
    main()
