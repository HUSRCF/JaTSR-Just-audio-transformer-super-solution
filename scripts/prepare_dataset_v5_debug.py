"""
JaT Benchmark V6 Speed Limit (æé™é€Ÿåº¦æµ‹è¯•ç‰ˆ)
================================================
åŸºäº Benchmark V6 é€»è¾‘ï¼Œå åŠ ä»¥ä¸‹ Buff:
1. [AMP] å¼€å¯ FP16 æ··åˆç²¾åº¦ (W7900 å¼ºé¡¹)ã€‚
2. [Compile] å¼€å¯ torch.compile(mode="reduce-overhead") (ç†è®ºæé™)ã€‚
3. [TF32] å¼€å¯ TensorFloat-32ã€‚

ç›®æ ‡: æµ‹è¯• W7900 åœ¨å¤„ç†å•æ›²æ—¶çš„ç†è®ºå¤©èŠ±æ¿é€Ÿåº¦ã€‚
æ³¨æ„: ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ Compile ä¼šèŠ±è´¹çº¦ 30-60s è¿›è¡Œç¼–è¯‘ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚
"""

import os
import torch
import torchaudio
import torchaudio.functional as AF
import numpy as np
from pathlib import Path
import random
import torch.multiprocessing as mp
import time
import math
import traceback
import dac
from audiotools import AudioSignal

# ==================== âš™ï¸ é…ç½® ====================
SOURCE_DIRS = ['1_source_audio', 'extra_audio']
DEBUG_DIR = "debug_output"

# ğŸš€ æé™é…ç½®
HIGH_SR = 48000
LOW_SR = 16000
CHUNK_DURATION = 15.0  # 15s åˆ‡ç‰‡ (æ¯” 30s æ›´ç¨³ï¼Œä¸”èƒ½è·‘å¤§ Batch)
DAC_BATCH_SIZE = 8     # å¼€å¯ AMP åæ˜¾å­˜å‡åŠï¼ŒBatch=8 åº”è¯¥å¾ˆè½»æ¾
DAC_MODEL_TYPE = "44khz"

# ==================== â±ï¸ è®¡æ—¶å™¨ ====================
class Timer:
    def __init__(self, name):
        self.name = name
        self.start = 0
        self.duration = 0
    def __enter__(self):
        self.start = time.time()
        return self
    def __exit__(self, *args):
        self.duration = time.time() - self.start

# ==================== ğŸ—ï¸ Worker ====================
def benchmark_worker(gpu_id, file_path, result_queue):
    log_prefix = f"[GPU {gpu_id}]"
    stats = {}
    
    try:
        print(f"{log_prefix} ğŸš€ å¯åŠ¨ä»»åŠ¡: {Path(file_path).name}")
        
        # 1. åˆå§‹åŒ–
        device = f'cuda:{gpu_id}'
        torch.cuda.set_device(device)
        # å¼€å¯ TF32
        torch.set_float32_matmul_precision('high')
        torch.cuda.reset_peak_memory_stats()
        
        with Timer("Load Model") as t_model:
            model_path = str(dac.utils.download(model_type=DAC_MODEL_TYPE))
            dac_model = dac.DAC.load(model_path).to(device)
            dac_model.eval()
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ å¼€å¯ Compile ğŸ”¥ğŸ”¥ğŸ”¥
            print(f"{log_prefix} æ­£åœ¨ç¼–è¯‘æ¨¡å‹ (è¿™å¯èƒ½éœ€è¦å‡ åç§’)...")
            t_compile_start = time.time()
            try:
                dac_model = torch.compile(dac_model, mode="reduce-overhead")
            except Exception as e:
                print(f"{log_prefix} âš ï¸ ç¼–è¯‘å¤±è´¥: {e}")
            print(f"{log_prefix} ç¼–è¯‘æŒ‡ä»¤ä¸‹è¾¾å®Œæˆ (å®é™…ç¼–è¯‘å‘ç”Ÿåœ¨ç¬¬ä¸€æ¬¡æ¨ç†)")
            
        stats['model_load_time'] = t_model.duration

        # 2. åŠ è½½éŸ³é¢‘ (GPU é‡é‡‡æ ·)
        with Timer("Load & Resample") as t_load:
            # IO
            audio, sr = torchaudio.load(file_path)
            # ç«‹å³ä¸Š GPU
            audio = audio.to(device) 
            
            if audio.shape[0] > 1: audio = audio.mean(dim=0, keepdim=True)
            peak = audio.abs().max()
            if peak > 1.0: audio = audio / peak
            
            # GPU é‡é‡‡æ ·
            if sr != HIGH_SR:
                audio_hr = AF.resample(audio, orig_freq=sr, new_freq=HIGH_SR)
            else:
                audio_hr = audio
                
        stats['audio_load_time'] = t_load.duration
        total_samples = audio_hr.shape[1]
        duration_sec = total_samples / HIGH_SR
        print(f"{log_prefix} é¢„å¤„ç†å®Œæˆ: {duration_sec:.2f}séŸ³é¢‘")

        # 3. åˆ‡åˆ†
        chunk_samples = int(CHUNK_DURATION * HIGH_SR)
        chunks_hr = []
        num_chunks = math.ceil(total_samples / chunk_samples)
        pad_len = (num_chunks * chunk_samples) - total_samples
        
        audio_hr_padded = torch.nn.functional.pad(audio_hr, (0, pad_len))
        for i in range(num_chunks):
            start = i * chunk_samples
            chunks_hr.append(audio_hr_padded[:, start : start + chunk_samples])
            
        print(f"{log_prefix} åˆ‡åˆ†å®Œæˆ: {num_chunks} chunks")

        # 4. ç¼–ç  (AMP + Compile)
        latents_hr_list = []
        hop_length = None
        t_encode_start = time.time()
        
        # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
        torch.cuda.empty_cache()
        
        # é¢„çƒ­è®¡æ•°å™¨ (ç”¨äºå‰”é™¤ç¼–è¯‘æ—¶é—´)
        is_first_batch = True
        
        for i in range(0, len(chunks_hr), DAC_BATCH_SIZE):
            batch_list = chunks_hr[i : i + DAC_BATCH_SIZE]
            batch_tensor = torch.stack(batch_list)
            
            # LR æ¨¡æ‹Ÿ
            batch_lr = AF.resample(AF.resample(batch_tensor, HIGH_SR, LOW_SR), LOW_SR, HIGH_SR)
            if batch_lr.shape[-1] != batch_tensor.shape[-1]:
                 batch_lr = torch.nn.functional.pad(batch_lr, (0, batch_tensor.shape[-1] - batch_lr.shape[-1]))

            # ğŸ”¥ğŸ”¥ğŸ”¥ AMP ä¸Šä¸‹æ–‡ ğŸ”¥ğŸ”¥ğŸ”¥
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                
                def encode_helper(wav):
                    signal = AudioSignal(wav, sample_rate=HIGH_SR)
                    if dac_model.sample_rate != HIGH_SR:
                        signal = signal.resample(dac_model.sample_rate)
                    with torch.no_grad():
                        z, _, _, _, _ = dac_model.encode(signal.audio_data)
                    return z

                t_batch_start = time.time()
                
                z_hr = encode_helper(batch_tensor)
                z_lr = encode_helper(batch_lr)
                
                # åŒæ­¥ä»¥æµ‹é‡çœŸå®æ—¶é—´
                torch.cuda.synchronize()
                t_batch_end = time.time()
                
                if is_first_batch:
                    print(f"{log_prefix} ğŸ”¥ ç¬¬ä¸€ä¸ª Batch (å«ç¼–è¯‘) è€—æ—¶: {t_batch_end - t_batch_start:.3f}s")
                    is_first_batch = False
                else:
                    # æ‰“å°åç»­ Batch çš„é€Ÿåº¦æ„Ÿå—
                    print(f"{log_prefix} âš¡ï¸ Batch è€—æ—¶: {t_batch_end - t_batch_start:.3f}s")
                    pass

            if hop_length is None:
                hop_length = batch_tensor.shape[-1] / z_hr.shape[-1]

            for b in range(z_hr.shape[0]):
                latents_hr_list.append(z_hr[b].cpu())

        stats['encoding_time'] = time.time() - t_encode_start
        print(f"{log_prefix} ç¼–ç æ€»è€—æ—¶: {stats['encoding_time']:.3f}s")

        # 5. æ‹¼æ¥
        full_hr = torch.cat(latents_hr_list, dim=-1)
        valid_frames = int(total_samples / hop_length)
        full_hr = full_hr[..., :valid_frames]
        
        stats['status'] = 'success'
        stats['peak_memory'] = torch.cuda.max_memory_allocated(device) / 1024**3
        stats['realtime_factor'] = duration_sec / stats['encoding_time']
        stats['duration_sec'] = duration_sec
        
        result_queue.put((gpu_id, stats))

    except Exception as e:
        print(f"{log_prefix} âŒ Error: {e}")
        traceback.print_exc()
        result_queue.put((gpu_id, {'status': 'error', 'msg': str(e)}))

# ==================== Main ====================
def main():
    try: mp.set_start_method('spawn', force=True)
    except: pass
        
    print("=" * 60)
    print("ğŸš€ JaT Benchmark V6: Speed Limit Edition")
    print(f"âš™ï¸  Config: AMP=ON | Compile=ON | Batch={DAC_BATCH_SIZE}")
    print("=" * 60)
    
    os.makedirs(DEBUG_DIR, exist_ok=True)
    all_files = []
    for d in SOURCE_DIRS:
        if os.path.exists(d):
            all_files.extend([str(p) for p in Path(d).rglob('*') if p.suffix.lower() in ['.wav', '.flac', '.mp3']])
    
    if len(all_files) < 2: return
    random.shuffle(all_files)
    test_files = all_files[:2]
    
    ctx = mp.get_context('spawn')
    queue = ctx.Queue()
    procs = []
    
    for i in range(2):
        p = ctx.Process(target=benchmark_worker, args=(i, test_files[i], queue))
        p.start()
        procs.append(p)
        
    for p in procs: p.join()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æé™æ€§èƒ½æŠ¥å‘Š")
    print("=" * 60)
    while not queue.empty():
        gpu_id, s = queue.get()
        if s['status'] == 'success':
            print(f"GPU {gpu_id}: âœ…")
            print(f"  - éŸ³é¢‘é•¿åº¦:   {s['duration_sec']:.2f}s")
            print(f"  - ç¼–ç è€—æ—¶:   {s['encoding_time']:.3f}s (å«ç¼–è¯‘æ—¶é—´)")
            print(f"  - å®æ—¶å€ç‡:   {s['realtime_factor']:.2f}x Realtime")
            print(f"  - æ˜¾å­˜å³°å€¼:   {s['peak_memory']:.2f} GB")
            print(f"  *å¦‚æœä¸å«é¦–Batchç¼–è¯‘ï¼Œé€Ÿåº¦ä¼šæ›´å¿«*")

if __name__ == '__main__':
    main()